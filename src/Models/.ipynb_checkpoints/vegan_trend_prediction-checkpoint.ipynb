{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76508cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "import findspark\n",
    "# initialize findspark with spark directory\n",
    "findspark.init(\"C:\\Program Files\\Spark\\spark-3.3.1-bin-hadoop3\")\n",
    "#findspark.init(\"/Users/wouterdewitte/spark/\")\n",
    "# import pyspark\n",
    "import pyspark\n",
    "# create spark context\n",
    "sc = pyspark.SparkContext()\n",
    "# create spark session \n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99192d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os \n",
    "import pickle\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pytz\n",
    "import emojis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import array_contains\n",
    "import matplotlib.pyplot as plt \n",
    "import emojis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import plotly.express as px\n",
    "from pandas.tseries.holiday import nearest_workday, \\\n",
    "    AbstractHolidayCalendar, Holiday, \\\n",
    "    USMartinLutherKingJr, USPresidentsDay, GoodFriday, \\\n",
    "    USMemorialDay, USLaborDay, USThanksgivingDay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dafa38",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422dcdae",
   "metadata": {},
   "source": [
    "In this notebook we will buid a model that predicts if the trend of a certain topic goes up or down on a certain day based on Twitter data of that day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1943e2",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ffa5e6",
   "metadata": {},
   "source": [
    "### 1.1 Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0a3d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read trend data \n",
    "trend = spark.read.csv(\".././../data/Google_trends/daily_trends.csv\", header=True, inferSchema=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3be47e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: timestamp, dependent_vegan: int]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae6b34ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+\n",
      "|               date|dependent_vegan|\n",
      "+-------------------+---------------+\n",
      "|2021-10-04 00:00:00|              1|\n",
      "|2021-10-05 00:00:00|              1|\n",
      "|2021-10-06 00:00:00|              1|\n",
      "|2021-10-07 00:00:00|              1|\n",
      "|2021-10-08 00:00:00|              1|\n",
      "|2021-10-09 00:00:00|              0|\n",
      "|2021-10-10 00:00:00|              0|\n",
      "|2021-10-11 00:00:00|              0|\n",
      "|2021-10-12 00:00:00|              0|\n",
      "|2021-10-13 00:00:00|              0|\n",
      "|2021-10-14 00:00:00|              0|\n",
      "|2021-10-15 00:00:00|              1|\n",
      "|2021-10-16 00:00:00|              1|\n",
      "|2021-10-17 00:00:00|              0|\n",
      "|2021-10-18 00:00:00|              1|\n",
      "|2021-10-19 00:00:00|              0|\n",
      "|2021-10-20 00:00:00|              0|\n",
      "|2021-10-21 00:00:00|              1|\n",
      "|2021-10-22 00:00:00|              1|\n",
      "|2021-10-23 00:00:00|              1|\n",
      "|2021-10-24 00:00:00|              0|\n",
      "|2021-10-25 00:00:00|              0|\n",
      "|2021-10-26 00:00:00|              0|\n",
      "|2021-10-27 00:00:00|              0|\n",
      "|2021-10-28 00:00:00|              1|\n",
      "|2021-10-29 00:00:00|              1|\n",
      "|2021-10-30 00:00:00|              1|\n",
      "|2021-10-31 00:00:00|              0|\n",
      "|2021-11-01 00:00:00|              0|\n",
      "|2021-11-02 00:00:00|              1|\n",
      "|2021-11-03 00:00:00|              1|\n",
      "|2021-11-04 00:00:00|              0|\n",
      "|2021-11-05 00:00:00|              1|\n",
      "|2021-11-06 00:00:00|              0|\n",
      "|2021-11-07 00:00:00|              0|\n",
      "|2021-11-08 00:00:00|              1|\n",
      "|2021-11-09 00:00:00|              0|\n",
      "|2021-11-10 00:00:00|              1|\n",
      "|2021-11-11 00:00:00|              0|\n",
      "|2021-11-12 00:00:00|              1|\n",
      "|2021-11-13 00:00:00|              1|\n",
      "|2021-11-14 00:00:00|              0|\n",
      "|2021-11-15 00:00:00|              1|\n",
      "|2021-11-16 00:00:00|              0|\n",
      "|2021-11-17 00:00:00|              1|\n",
      "|2021-11-18 00:00:00|              0|\n",
      "|2021-11-19 00:00:00|              1|\n",
      "|2021-11-20 00:00:00|              1|\n",
      "|2021-11-21 00:00:00|              0|\n",
      "|2021-11-22 00:00:00|              1|\n",
      "|2021-11-23 00:00:00|              1|\n",
      "|2021-11-24 00:00:00|              1|\n",
      "|2021-11-25 00:00:00|              0|\n",
      "|2021-11-26 00:00:00|              1|\n",
      "|2021-11-27 00:00:00|              0|\n",
      "|2021-11-28 00:00:00|              0|\n",
      "|2021-11-29 00:00:00|              0|\n",
      "|2021-11-30 00:00:00|              1|\n",
      "|2021-12-01 00:00:00|              1|\n",
      "|2021-12-02 00:00:00|              0|\n",
      "|2021-12-03 00:00:00|              1|\n",
      "|2021-12-04 00:00:00|              0|\n",
      "|2021-12-05 00:00:00|              0|\n",
      "|2021-12-06 00:00:00|              0|\n",
      "|2021-12-07 00:00:00|              1|\n",
      "|2021-12-08 00:00:00|              0|\n",
      "|2021-12-09 00:00:00|              0|\n",
      "|2021-12-10 00:00:00|              1|\n",
      "|2021-12-11 00:00:00|              0|\n",
      "|2021-12-12 00:00:00|              0|\n",
      "|2021-12-13 00:00:00|              0|\n",
      "|2021-12-14 00:00:00|              0|\n",
      "|2021-12-15 00:00:00|              1|\n",
      "|2021-12-16 00:00:00|              0|\n",
      "|2021-12-17 00:00:00|              1|\n",
      "|2021-12-18 00:00:00|              1|\n",
      "|2021-12-19 00:00:00|              0|\n",
      "|2021-12-20 00:00:00|              0|\n",
      "|2021-12-21 00:00:00|              1|\n",
      "|2021-12-22 00:00:00|              1|\n",
      "|2021-12-23 00:00:00|              1|\n",
      "|2021-12-24 00:00:00|              0|\n",
      "|2021-12-25 00:00:00|              0|\n",
      "|2021-12-26 00:00:00|              0|\n",
      "|2021-12-27 00:00:00|              1|\n",
      "|2021-12-28 00:00:00|              1|\n",
      "|2021-12-29 00:00:00|              0|\n",
      "|2021-12-30 00:00:00|              1|\n",
      "|2021-12-31 00:00:00|              1|\n",
      "|2022-01-01 00:00:00|              1|\n",
      "|2022-01-02 00:00:00|              0|\n",
      "|2022-01-03 00:00:00|              0|\n",
      "|2022-01-04 00:00:00|              1|\n",
      "|2022-01-05 00:00:00|              0|\n",
      "|2022-01-06 00:00:00|              1|\n",
      "|2022-01-07 00:00:00|              1|\n",
      "|2022-01-08 00:00:00|              0|\n",
      "|2022-01-09 00:00:00|              0|\n",
      "|2022-01-10 00:00:00|              1|\n",
      "|2022-01-11 00:00:00|              1|\n",
      "+-------------------+---------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "w = Window().partitionBy().orderBy(col(\"date\"))\n",
    "trend.withColumn(\"dependent_vegan\", lag(\"dependent_vegan\", -1, 0).over(w)).show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb226e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "trend.createOrReplaceTempView(\"trendSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0b9d77",
   "metadata": {},
   "source": [
    "The binary variable indicates if the trend goes up or down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aff149",
   "metadata": {},
   "source": [
    "### 1.2 Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795db881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data dir\n",
    "data_dir = \"../../data/Topic/\"\n",
    "\n",
    "# get all twitter files\n",
    "tweet_files = [os.path.join(data_dir, obs) for obs in os.listdir(data_dir)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2953fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import twitter data \n",
    "#twitter_df = spark.read.json(tweet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce5a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_hashtags = [\"vegan\"]\n",
    "\n",
    "data_dir = \".././../data/Topic/\"\n",
    "tweet_files = [os.path.join(data_dir, obs) for obs in os.listdir(data_dir)]\n",
    "files_hashtags = [file for file in tweet_files if (file.find(list_hashtags[0]) != -1)]             \n",
    "twitter_df = spark.read.option(\"multiline\",\"true\").json(files_hashtags) \n",
    "twitter_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select interesting features\n",
    "twitter_df = twitter_df.select(F.col('user.name'),\n",
    "                                F.col('user.screen_name'),\n",
    "                                F.col('user.followers_count'),\n",
    "                                F.col('user.following'),\n",
    "                                F.col('user.statuses_count'),\n",
    "                                F.col('user.listed_count'),\n",
    "                                F.col('created_at'),\n",
    "                                F.col('full_text'),\n",
    "                                F.col('entities.hashtags'),\n",
    "                                F.col('favorite_count'),\n",
    "                                F.col('retweet_count'),\n",
    "                                F.col('user.friends_count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ad4622",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b9dd70",
   "metadata": {},
   "source": [
    "### 2.1 Check time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96607a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert Twitter date string format\n",
    "def getDate(date):\n",
    "    if date is not None:\n",
    "        return str(datetime.strptime(date,'%a %b %d %H:%M:%S +0000 %Y').replace(tzinfo=pytz.UTC).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# UDF declaration\n",
    "date_udf = F.udf(getDate, StringType())\n",
    "\n",
    "# apply udf\n",
    "twitter_df = twitter_df.withColumn('post_created_at', F.to_utc_timestamp(date_udf(\"created_at\"), \"UTC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first post\n",
    "first_post = F.min('post_created_at').alias('earliest')\n",
    "# get latest post\n",
    "latest_post = F.max('post_created_at').alias('latest')\n",
    "# show tweet period in our dataset\n",
    "twitter_df.select(first_post, latest_post).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f4e9b",
   "metadata": {},
   "source": [
    "### 2.2 Remove retweets and duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all retweets from dataset\n",
    "no_retweets_df = twitter_df.filter(~F.col(\"full_text\").startswith(\"RT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0be0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first sort no_retweets_df based on date in chronological order (most recent ones on top)\n",
    "no_retweets_sorted_df = no_retweets_df.sort(\"post_created_at\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of observations before dropping duplicates\n",
    "no_retweets_sorted_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf73d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates based on tweet text and the profile it was posted from\n",
    "final_no_duplicates_df = no_retweets_sorted_df.drop_duplicates([\"full_text\", \"screen_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a33594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of observations after dropping duplicates\n",
    "final_no_duplicates_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908138e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename dataframe\n",
    "final_twitter_df = final_no_duplicates_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef6316",
   "metadata": {},
   "source": [
    "## 3. Independent Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165908d",
   "metadata": {},
   "source": [
    "For our independent variables we need to design a pipeline that transforms the data into the desired aggregated metrics per day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15c1f5",
   "metadata": {},
   "source": [
    "### 3.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39fa87",
   "metadata": {},
   "source": [
    "#### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050976b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to count hashtags\n",
    "def get_hashtags(tokenized_text):\n",
    "    counter = 0\n",
    "    for word in tokenized_text:\n",
    "        if \"#\" in word:\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b238392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to count mentions\n",
    "def get_mentions(tokenized_text):\n",
    "    counter = 0\n",
    "    for word in tokenized_text:\n",
    "        if \"@\" in word:\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c9c5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to count exclamation marks\n",
    "def get_exclamation_marks(tokenized_text):\n",
    "    counter = 0\n",
    "    for word in tokenized_text:\n",
    "        if \"!\" in word:\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d141323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to count number of emojis used\n",
    "def emoji_counter(text):\n",
    "    nr_emojis = emojis.count(text)\n",
    "    return(nr_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3079f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate engagement rate\n",
    "def engagement_rate(favorite_count, retweet_count, followers_count):\n",
    "    if(followers_count == 0):\n",
    "        eng_rate = 0\n",
    "    else:\n",
    "        eng_rate = (favorite_count + retweet_count)/followers_count\n",
    "    \n",
    "    return eng_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49cf68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register functions as udf\n",
    "get_hashtags_UDF = F.udf(get_hashtags, IntegerType())\n",
    "get_mentions_UDF = F.udf(get_mentions, IntegerType())\n",
    "get_exclamation_marks_UDF = F.udf(get_exclamation_marks, IntegerType())\n",
    "emoji_counter_UDF = F.udf(emoji_counter, IntegerType())\n",
    "engagement_rate_UDF = F.udf(engagement_rate, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply functions to create new features\n",
    "final_twitter_df = final_twitter_df.withColumn(\"emoji_count\", emoji_counter_UDF(\"full_text\")) \\\n",
    "        .withColumn(\"text_tokenized\", F.split(\"full_text\", \" \")) \\\n",
    "        .withColumn(\"num_words\", F.size(\"text_tokenized\")) \\\n",
    "        .withColumn(\"num_hashtags\", get_hashtags_UDF(\"text_tokenized\")) \\\n",
    "        .withColumn(\"num_mentions\", get_mentions_UDF(\"text_tokenized\")) \\\n",
    "        .withColumn(\"num_exclamation_marks\", get_exclamation_marks_UDF(\"text_tokenized\")) \\\n",
    "        .withColumn(\"engagement_rate\", engagement_rate_UDF(\"favorite_count\", \"retweet_count\", \"followers_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7219ef0",
   "metadata": {},
   "source": [
    "#### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b483df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for english tweets (NOTE: for the assignment you can translate non-english tweets using an API)\n",
    "final_twitter_df = final_twitter_df.filter(F.col(\"lang\") == \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72531af2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check number of observations\n",
    "final_twitter_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21463c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to clean text\n",
    "def clean_text(string):\n",
    "    \n",
    "    # define numbers\n",
    "    NUMBERS = '0123456789'\n",
    "    PUNCT = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    \n",
    "    # convert text to lower case\n",
    "    cleaned_string = string.lower()\n",
    "    \n",
    "    # remove URLS\n",
    "    cleaned_string = re.sub(r'http\\S+', ' ', cleaned_string)\n",
    "    \n",
    "    # replace emojis by words\n",
    "    cleaned_string = emojis.decode(cleaned_string)\n",
    "    cleaned_string = cleaned_string.replace(\":\",\" \").replace(\"_\",\" \")\n",
    "    cleaned_string = ' '.join(cleaned_string.split())\n",
    "    \n",
    "    # remove numbers\n",
    "    cleaned_string = \"\".join([char for char in cleaned_string if char not in NUMBERS])\n",
    "    \n",
    "    # remove punctuation\n",
    "    cleaned_string = \"\".join([char for char in cleaned_string if char not in PUNCT])\n",
    "    \n",
    "    # remove words conisting of one character (or less)\n",
    "    cleaned_string = ' '.join([w for w in cleaned_string.split() if len(w) > 1])\n",
    "    \n",
    "    # return\n",
    "    return(cleaned_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to udf\n",
    "clean_text_udf = F.udf(clean_text, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean string\n",
    "final_twitter_df = final_twitter_df.withColumn(\"cleaned_text\", clean_text_udf(F.col(\"full_text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c608f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "final_twitter_df.select(\"full_text\", \"cleaned_text\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bdf59",
   "metadata": {},
   "source": [
    "#### Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b1457b",
   "metadata": {},
   "source": [
    "VADER sentimental analysis relies on a dictionary that maps lexical features to emotion intensities known as sentiment scores. The sentiment score of a text can be obtained by summing up the intensity of each word in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c817a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using the vaderSentiment package \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ff1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to extract the sentiment\n",
    "def get_sentiment(sentence):\n",
    "\n",
    "    # initialize sentiment analyzer\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # get sentiment dict\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    \n",
    "    # get positive sentiment score\n",
    "    pos_sentiment = sentiment_dict[\"pos\"]\n",
    "    \n",
    "    # return positive sentiment score\n",
    "    return(pos_sentiment)\n",
    "\n",
    "get_sentiment_udf = udf(get_sentiment, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006cc221",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_twitter_df = final_twitter_df.withColumn(\"sentiment_vader\", get_sentiment_udf(F.col(\"cleaned_text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4304a09d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_twitter_df.select(\"cleaned_text\", \"sentiment_vader\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d493ac0",
   "metadata": {},
   "source": [
    "#### TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b22e97",
   "metadata": {},
   "source": [
    "TextBlob returns polarity and subjectivity of a sentence. \n",
    "\n",
    "**Polarity** lies between [-1,1],  -1 defines a negative sentiment and 1 defines a positive sentiment.  \n",
    "\n",
    "**Subjectivity** quantifies the amount of personal opinion and factual information contained in the text. Subjectivity lies between [0,1]. The higher subjectivity means that the text contains personal opinion rather than factual information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad40a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use polarity and subjectivity from TextBlob \n",
    "#https://textblob.readthedocs.io/en/dev/\n",
    "from textblob import TextBlob\n",
    "\n",
    "# define function to get polarity score of text document\n",
    "def get_polarity(row):\n",
    "    textBlob_review = TextBlob(row)\n",
    "    return textBlob_review.sentiment[0]\n",
    "# define function to get subjectivity score of text document\n",
    "def get_subjectivity(row):\n",
    "    textBlob_review = TextBlob(row)\n",
    "    return textBlob_review.sentiment[1]\n",
    "get_polarity_udf = F.udf(get_polarity, DoubleType())\n",
    "get_subjectivity_udf = F.udf(get_subjectivity, DoubleType())\n",
    "\n",
    "final_twitter_df = final_twitter_df.withColumn('polarity', get_polarity_udf(F.col('cleaned_text')))\\\n",
    "        .withColumn('subjectivity', get_subjectivity_udf(F.col('cleaned_text')))\n",
    "\n",
    "final_twitter_df.select(\"cleaned_text\", \"sentiment_vader\", \"polarity\", \"subjectivity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60590543",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_twitter_df = final_twitter_df.withColumn('polarity', get_polarity_udf(F.col('cleaned_text')))\\\n",
    "        .withColumn('subjectivity', get_subjectivity_udf(F.col('cleaned_text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa86eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_twitter_df.select(\"cleaned_text\", \"sentiment_vader\", \"polarity\", \"subjectivity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "final_twitter_df.createOrReplaceTempView(\"twitterSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cf7e6",
   "metadata": {},
   "source": [
    "### 3.1 Volume of tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "volume = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, COUNT(*) as volume \\\n",
    "                                    FROM twitterSQL \\\n",
    "                                    GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                                    ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7816d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show \n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "volume.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072ecd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "volume.createOrReplaceTempView(\"volumeSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb81a7",
   "metadata": {},
   "source": [
    "### 3.2 Average likes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e49f2",
   "metadata": {},
   "source": [
    "We exclude tweets with 0 likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28099a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_likes = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(favorite_count) as avg_likes \\\n",
    "                           FROM twitterSQL \\\n",
    "                           WHERE favorite_count > 0 \\\n",
    "                           GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                           ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67edf65d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show \n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_likes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6003b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "avg_likes.createOrReplaceTempView(\"avg_likesSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa4e0b",
   "metadata": {},
   "source": [
    "### 3.3 Average Retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff829814",
   "metadata": {},
   "source": [
    "We exclude tweets with 0 retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b17a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_retweets = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(retweet_count) as avg_retweets \\\n",
    "                          FROM twitterSQL \\\n",
    "                          WHERE retweet_count > 0 \\\n",
    "                          GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                          ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a6f578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show \n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_retweets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e76dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "avg_retweets.createOrReplaceTempView(\"avg_retweetsSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c11de2",
   "metadata": {},
   "source": [
    "### 3.4 Average Engagement rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271c4c1",
   "metadata": {},
   "source": [
    "We define engagement rate of a tweet as the sum of likes and retweets divided by the amount of followers of the account that sent out the tweet. For our purpose we will take the avergage engagement rate per day. We exclude accounts who have no followers and we only take tweets into account which are liked and retweeted at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_engagement_rate = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(engagement_rate) as avg_engagement_rate \\\n",
    "                                     FROM twitterSQL \\\n",
    "                                     GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                                     ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ebc1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_engagement_rate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2dfa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "avg_engagement_rate.createOrReplaceTempView(\"avg_engagement_rateSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea74252",
   "metadata": {},
   "source": [
    "### 3.5 Number of influencers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f77904a",
   "metadata": {},
   "source": [
    "We will calculate how many influencers actively tweeted a certain day. We define an influencer as someone with:\n",
    "- followers > 1000 \n",
    "- engagement_rate > 0.20 \n",
    "- weekly tweet frequency > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d92a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_influencers(follower_count_tresh, eng_rate_tresh, freq_week_tresh, data):\n",
    "\n",
    "    #df\n",
    "    df = data\n",
    "    \n",
    "    # get all users with their amount of followers\n",
    "    influencers = df.groupBy(\"screen_name\") \\\n",
    "                    .agg(first(\"followers_count\").alias(\"followers_count\"))\n",
    "\n",
    "    # average engagement rate for each user\n",
    "    eng_rate = df.withColumn('eng_rate', ((df['favorite_count'] + df['retweet_count'])/df['followers_count']))\n",
    "\n",
    "    eng_rate_user = eng_rate.groupBy(\"screen_name\") \\\n",
    "                            .agg(avg(\"eng_rate\").alias(\"eng_rate\"))\n",
    "\n",
    "    # average freq_weekly per user\n",
    "    freq_week = df.withColumn(\"year\", year(df[\"post_created_at\"]))\n",
    "    freq_week = freq_week.withColumn('week', weekofyear('post_created_at'))\n",
    "\n",
    "    freq_week = freq_week.groupBy('screen_name', 'year', 'week').agg(countDistinct(\"full_text\"))\\\n",
    "                    .withColumnRenamed(\"count(full_text)\", \"freq\") \\\n",
    "                        .sort('screen_name', 'year', 'week', ascending = True)\n",
    "    freq_week = freq_week.select('screen_name', 'freq')\n",
    "\n",
    "    freq_week = freq_week.groupby(\"screen_name\").agg(avg(freq_week.freq).alias('freq'))\n",
    "\n",
    "    # put the data together\n",
    "    data_joined = eng_rate_user.join(influencers, \"screen_name\").join(freq_week, \"screen_name\")\n",
    "\n",
    "    # filter the data\n",
    "    data_joined = data_joined.filter((data_joined.followers_count > follower_count_tresh) & (data_joined.eng_rate > eng_rate_tresh) & (data_joined.freq > freq_week_tresh))\n",
    "    \n",
    "    # show the data\n",
    "    data_joined.show()\n",
    "    return data_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df2e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "influencers = get_influencers(1000, 0.002, 2, final_twitter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acae7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "influencers.createOrReplaceTempView(\"influencersSQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "number_of_influencers = spark.sql(\" SELECT DATE_FORMAT(a.post_created_at, 'Y-M-dd') as date, COUNT(b.screen_name) as influencers \\\n",
    "                                    FROM twitterSQL a \\\n",
    "                                    RIGHT OUTER JOIN influencersSQL b ON a.screen_name = b.screen_name\\\n",
    "                                    GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                                    ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c3a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "number_of_influencers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd978455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "number_of_influencers.createOrReplaceTempView(\"number_of_influencersSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac84d0b6",
   "metadata": {},
   "source": [
    "### 3.6 Average Followers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_followers = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(followers_count) as avg_followers \\\n",
    "                          FROM twitterSQL \\\n",
    "                          WHERE followers_count > 0 \\\n",
    "                          GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                          ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbef568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_followers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecbe410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "number_of_influencers.createOrReplaceTempView(\"followersSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf1886a",
   "metadata": {},
   "source": [
    "### 3.7 Average Emoji Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4ae563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_emoji = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(emoji_count) as avg_emojis \\\n",
    "                          FROM twitterSQL \\\n",
    "                          GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                          ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_emoji.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "number_of_influencers.createOrReplaceTempView(\"emojiSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8e7d9",
   "metadata": {},
   "source": [
    "### 3.8 Avergae Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de782c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_words = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(num_words) as avg_words \\\n",
    "                          FROM twitterSQL \\\n",
    "                          GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                          ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "avg_words.createOrReplaceTempView(\"wordsSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d277253",
   "metadata": {},
   "source": [
    "### 3.9 Avergae Number of Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a35a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_hashtags = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(num_hashtags) as avg_hashtags \\\n",
    "                          FROM twitterSQL \\\n",
    "                          GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                          ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf351dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_hashtags.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207697b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "avg_hashtags.createOrReplaceTempView(\"hashtagsSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ef6de",
   "metadata": {},
   "source": [
    "### 3.10 Average Number of Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8408634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_mentions = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(num_mentions) as avg_mentions \\\n",
    "                          FROM twitterSQL \\\n",
    "                          GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                          ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_mentions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935eef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "avg_mentions.createOrReplaceTempView(\"mentionsSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58726060",
   "metadata": {},
   "source": [
    "### 3.11 Average Number of Exclamation Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319bfefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_marks = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(num_exclamation_marks) as avg_exclamation_marks \\\n",
    "                          FROM twitterSQL \\\n",
    "                          GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                          ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6abfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_marks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c522446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "avg_marks.createOrReplaceTempView(\"marksSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95f264",
   "metadata": {},
   "source": [
    "### 3.12 Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_sentiment = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(sentiment_vader) as avg_sentiment \\\n",
    "                          FROM twitterSQL \\\n",
    "                          GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                          ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3087ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_sentiment.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "avg_sentiment.createOrReplaceTempView(\"sentimentSQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237688b5",
   "metadata": {},
   "source": [
    "### 3.13 Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1778ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_polarity = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(polarity) as avg_polarity \\\n",
    "                          FROM twitterSQL \\\n",
    "                          GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                          ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9874c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_polarity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "avg_polarity.createOrReplaceTempView(\"polaritySQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb6f32",
   "metadata": {},
   "source": [
    "### 3.13 Subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d11cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the relevant data\n",
    "avg_subjectivity = spark.sql(\"SELECT DATE_FORMAT(post_created_at, 'Y-M-dd') as date, AVG(subjectivity) as avg_subjectivity \\\n",
    "                          FROM twitterSQL \\\n",
    "                          GROUP BY DATE_FORMAT(post_created_at, 'Y-M-dd') \\\n",
    "                          ORDER BY DATE_FORMAT(post_created_at, 'Y-M-dd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bcadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n",
    "avg_subjectivity.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "avg_subjectivity.createOrReplaceTempView(\"subjectivitySQL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b60dd",
   "metadata": {},
   "source": [
    "## 4. Basetable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basetable\n",
    "basetable = volume.join(avg_likes, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_retweets, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_engagement_rate, \"date\", how=\"inner\") \\\n",
    "                    .join(number_of_influencers, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_followers, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_emoji, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_words, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_hashtags, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_mentions, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_marks, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_sentiment, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_polarity, \"date\", how=\"inner\") \\\n",
    "                    .join(avg_subjectivity, \"date\", how=\"inner\") \\\n",
    "                    .join(trend, \"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the basetable\n",
    "basetable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable = basetable.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41acbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export basetable as a .json file\n",
    "basetable.to_json(\"./../../data/basetable_vegan_trend_prediction.json\", orient=\"records\", force_ascii=False, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4339a9e4",
   "metadata": {},
   "source": [
    "#### Read table in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "426afab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the saved basetable (.json)\n",
    "basetable_df = spark.read.json(\"./../../data/basetable_vegan_trend_prediction.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7cdbd3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+---------------------+----------------+------------+-------------+------------+------------+-------------+-------------+----------------+-------------+----------+---------------+-----------+------+\n",
      "|  avg_emojis|avg_engagement_rate|avg_exclamation_marks|   avg_followers|avg_hashtags|    avg_likes|avg_mentions|avg_polarity| avg_retweets|avg_sentiment|avg_subjectivity|    avg_words|      date|dependent_vegan|influencers|volume|\n",
      "+------------+-------------------+---------------------+----------------+------------+-------------+------------+------------+-------------+-------------+----------------+-------------+----------+---------------+-----------+------+\n",
      "|0.4280180762|       0.0303423202|         0.2091672046| 7811.1375488918| 1.506132989| 9.5102286402|1.2246610717|0.1127719889| 3.3629343629| 0.1322898644|    0.4252520269|25.9561007101|2021-11-03|            1.0|        120|  1549|\n",
      "|0.8352165725|       0.0330735083|         0.3549905838| 3640.0143403442|6.1186440678|18.8860544218| 0.565913371|0.1794901069|10.7292307692| 0.1655160075|     0.415197219|25.7542372881| 2022-8-15|            0.0|        119|  1062|\n",
      "|0.5795454545|       0.0090354097|         0.3522727273|  6038.816091954|6.6363636364| 5.2222222222|0.2613636364|0.2407288701|      2.59375| 0.1910340909|    0.4031603386|24.8068181818| 2022-6-13|            0.0|          4|    88|\n",
      "|0.9856512141|       0.0808854463|         0.3498896247| 6134.9597315436|6.0794701987|14.1910946197| 0.614790287|0.1695837324| 6.1367781155| 0.1527108168|    0.4074819656|25.4150110375| 2022-8-14|            1.0|         89|   906|\n",
      "|0.8306828812|       0.0479265599|         0.4237605239| 4375.8903591682| 6.506080449|12.4626086957|  0.40505145|0.2141369687| 6.7068062827| 0.1783002806|    0.4308005243|25.5098222638| 2022-7-07|            0.0|         76|  1069|\n",
      "| 0.737394958|        0.025709073|         0.3865546218| 5702.7358892439|5.6575630252|12.0820512821|0.4978991597|0.2091006325| 6.2695924765| 0.1690987395|    0.4259372933|24.4957983193| 2022-5-26|            1.0|         78|   952|\n",
      "|0.4393939394|       0.0213452919|         0.2095959596| 3704.7251308901|1.6767676768|14.8789237668|1.0934343434|0.1270217157| 7.6951219512| 0.1265151515|     0.460761597|29.3484848485|2021-10-27|            0.0|         32|   396|\n",
      "| 0.724847561|       0.0332267214|         0.3208841463| 5130.6095089634| 4.293445122|19.2364394993|0.5861280488|0.1551534023|11.4625668449| 0.1496036585|    0.4115203241|     25.21875| 2022-3-13|            1.0|        129|  1312|\n",
      "|0.7159804606|       0.0280713247|         0.3914863922| 9470.1829096045|5.8457780879|15.8010012516|0.5150034892|0.2072232474| 5.5292929293|  0.154718074|    0.4430629996|25.9902302861| 2022-1-10|            0.0|         93|  1433|\n",
      "|  0.73657289|       0.0203645056|         0.3631713555| 4784.1841432225|5.9488491049|13.6784140969|0.3708439898| 0.194723533|       10.312|  0.161826087|    0.4216710856| 25.631713555| 2022-7-15|            1.0|         40|   391|\n",
      "|0.6647058824|       0.0381538045|         0.3008403361| 5410.1367965368|6.4268907563|14.4456140351|0.3487394958|0.1841718318| 6.7661290323| 0.1661428571|    0.4244741044|25.5344537815| 2022-4-16|            1.0|         81|  1190|\n",
      "|0.8772678762|       0.0323760468|         0.3468516542| 3448.8548387097|5.7097118463|21.7274305556|  0.37886873|0.1865421411| 7.6457680251| 0.1656638207|    0.4088177264|23.9786552828| 2022-5-01|            1.0|        100|   937|\n",
      "|0.4488696263|       0.0345402634|         0.2179922689|14339.8916508088|0.9578306197|12.6662473795|0.9076959119|0.1185524159| 6.7667757774| 0.1361419702|    0.4165406415| 23.792432939| 2022-8-03|            1.0|        356|  8537|\n",
      "|0.6615776081|       0.0342467786|         0.3702290076| 6531.6858974359|5.6857506361|17.1735159817|0.4541984733|0.2004823474| 9.9288537549| 0.1699516539|    0.4254932817|24.3117048346| 2022-5-29|            1.0|         57|   786|\n",
      "| 0.781512605|       0.0182628516|         0.3538748833| 8110.8289224953|5.8394024276|12.9023569024|0.5116713352|0.1872391473| 8.1531531532| 0.1654939309|    0.4153168586|24.9234360411| 2022-8-31|            1.0|         90|  1071|\n",
      "|1.1111111111|       0.0156431646|         0.3055555556|14294.6388888889|6.8333333333|          5.0|0.7777777778| 0.235408235|        3.875| 0.2154166667|    0.4191615509|23.6666666667|2021-12-06|            0.0|          2|    36|\n",
      "| 0.764604811|        0.031361015|         0.3771477663|15252.2026086957|5.6984536082|14.5280373832| 0.631443299|0.1800931746|  5.389380531| 0.1546709622|    0.4198680733|25.1305841924| 2022-9-07|            0.0|         93|  1164|\n",
      "|0.7833333333|       0.0357992132|         0.3392156863| 5466.7223880597|5.8333333333|21.1176470588|0.5392156863| 0.192187921| 7.3236151603| 0.1549637255|    0.4176970414|24.1401960784| 2022-9-03|            1.0|         79|  1020|\n",
      "|1.0416666667|       0.0219217233|                 0.25| 2650.4166666667|6.1666666667|          1.2|        0.25|0.1327958847|          1.5| 0.1022916667|    0.4484988102|22.1666666667| 2022-6-03|            1.0|          1|    24|\n",
      "|      0.7025|       0.0263312531|         0.2691666667| 5702.8761583825|5.1641666667|         18.0|0.6066666667|0.1758793604| 7.7543859649| 0.1590216667|    0.4124599683|      25.5125| 2022-6-26|            1.0|        107|  1200|\n",
      "+------------+-------------------+---------------------+----------------+------------+-------------+------------+------------+-------------+-------------+----------------+-------------+----------+---------------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "basetable_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "effcb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SQL view\n",
    "basetable_df.createOrReplaceTempView(\"basetableSQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68a49b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = spark.sql(\"SELECT date, volume,avg_retweets, dependent_vegan \\\n",
    "                  FROM basetableSQL\"\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d15bb22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------+---------------+\n",
      "|      date|volume| avg_retweets|dependent_vegan|\n",
      "+----------+------+-------------+---------------+\n",
      "|2021-11-03|  1549| 3.3629343629|            1.0|\n",
      "| 2022-8-15|  1062|10.7292307692|            0.0|\n",
      "| 2022-6-13|    88|      2.59375|            0.0|\n",
      "| 2022-8-14|   906| 6.1367781155|            1.0|\n",
      "| 2022-7-07|  1069| 6.7068062827|            0.0|\n",
      "| 2022-5-26|   952| 6.2695924765|            1.0|\n",
      "|2021-10-27|   396| 7.6951219512|            0.0|\n",
      "| 2022-3-13|  1312|11.4625668449|            1.0|\n",
      "| 2022-1-10|  1433| 5.5292929293|            0.0|\n",
      "| 2022-7-15|   391|       10.312|            1.0|\n",
      "| 2022-4-16|  1190| 6.7661290323|            1.0|\n",
      "| 2022-5-01|   937| 7.6457680251|            1.0|\n",
      "| 2022-8-03|  8537| 6.7667757774|            1.0|\n",
      "| 2022-5-29|   786| 9.9288537549|            1.0|\n",
      "| 2022-8-31|  1071| 8.1531531532|            1.0|\n",
      "|2021-12-06|    36|        3.875|            0.0|\n",
      "| 2022-9-07|  1164|  5.389380531|            0.0|\n",
      "| 2022-9-03|  1020| 7.3236151603|            1.0|\n",
      "| 2022-6-03|    24|          1.5|            1.0|\n",
      "| 2022-6-26|  1200| 7.7543859649|            1.0|\n",
      "+----------+------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fc7ca",
   "metadata": {},
   "source": [
    "Look at the total number of observations in the basetable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58343ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9612cd2",
   "metadata": {},
   "source": [
    "## 5. split train and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a1ea0e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_emojis</th>\n",
       "      <th>avg_engagement_rate</th>\n",
       "      <th>avg_exclamation_marks</th>\n",
       "      <th>avg_followers</th>\n",
       "      <th>avg_hashtags</th>\n",
       "      <th>avg_likes</th>\n",
       "      <th>avg_mentions</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>avg_retweets</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>avg_subjectivity</th>\n",
       "      <th>avg_words</th>\n",
       "      <th>date</th>\n",
       "      <th>dependent_vegan</th>\n",
       "      <th>influencers</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428018</td>\n",
       "      <td>0.030342</td>\n",
       "      <td>0.209167</td>\n",
       "      <td>7811.137549</td>\n",
       "      <td>1.506133</td>\n",
       "      <td>9.510229</td>\n",
       "      <td>1.224661</td>\n",
       "      <td>0.112772</td>\n",
       "      <td>3.362934</td>\n",
       "      <td>0.132290</td>\n",
       "      <td>0.425252</td>\n",
       "      <td>25.956101</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.835217</td>\n",
       "      <td>0.033074</td>\n",
       "      <td>0.354991</td>\n",
       "      <td>3640.014340</td>\n",
       "      <td>6.118644</td>\n",
       "      <td>18.886054</td>\n",
       "      <td>0.565913</td>\n",
       "      <td>0.179490</td>\n",
       "      <td>10.729231</td>\n",
       "      <td>0.165516</td>\n",
       "      <td>0.415197</td>\n",
       "      <td>25.754237</td>\n",
       "      <td>2022-8-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579545</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.352273</td>\n",
       "      <td>6038.816092</td>\n",
       "      <td>6.636364</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>0.240729</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>0.191034</td>\n",
       "      <td>0.403160</td>\n",
       "      <td>24.806818</td>\n",
       "      <td>2022-6-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985651</td>\n",
       "      <td>0.080885</td>\n",
       "      <td>0.349890</td>\n",
       "      <td>6134.959732</td>\n",
       "      <td>6.079470</td>\n",
       "      <td>14.191095</td>\n",
       "      <td>0.614790</td>\n",
       "      <td>0.169584</td>\n",
       "      <td>6.136778</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>0.407482</td>\n",
       "      <td>25.415011</td>\n",
       "      <td>2022-8-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.830683</td>\n",
       "      <td>0.047927</td>\n",
       "      <td>0.423761</td>\n",
       "      <td>4375.890359</td>\n",
       "      <td>6.506080</td>\n",
       "      <td>12.462609</td>\n",
       "      <td>0.405051</td>\n",
       "      <td>0.214137</td>\n",
       "      <td>6.706806</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.430801</td>\n",
       "      <td>25.509822</td>\n",
       "      <td>2022-7-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_emojis  avg_engagement_rate  avg_exclamation_marks  avg_followers  \\\n",
       "0    0.428018             0.030342               0.209167    7811.137549   \n",
       "1    0.835217             0.033074               0.354991    3640.014340   \n",
       "2    0.579545             0.009035               0.352273    6038.816092   \n",
       "3    0.985651             0.080885               0.349890    6134.959732   \n",
       "4    0.830683             0.047927               0.423761    4375.890359   \n",
       "\n",
       "   avg_hashtags  avg_likes  avg_mentions  avg_polarity  avg_retweets  \\\n",
       "0      1.506133   9.510229      1.224661      0.112772      3.362934   \n",
       "1      6.118644  18.886054      0.565913      0.179490     10.729231   \n",
       "2      6.636364   5.222222      0.261364      0.240729      2.593750   \n",
       "3      6.079470  14.191095      0.614790      0.169584      6.136778   \n",
       "4      6.506080  12.462609      0.405051      0.214137      6.706806   \n",
       "\n",
       "   avg_sentiment  avg_subjectivity  avg_words        date  dependent_vegan  \\\n",
       "0       0.132290          0.425252  25.956101  2021-11-03              1.0   \n",
       "1       0.165516          0.415197  25.754237   2022-8-15              0.0   \n",
       "2       0.191034          0.403160  24.806818   2022-6-13              0.0   \n",
       "3       0.152711          0.407482  25.415011   2022-8-14              1.0   \n",
       "4       0.178300          0.430801  25.509822   2022-7-07              0.0   \n",
       "\n",
       "   influencers  volume  \n",
       "0          120    1549  \n",
       "1          119    1062  \n",
       "2            4      88  \n",
       "3           89     906  \n",
       "4           76    1069  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20f7f5",
   "metadata": {},
   "source": [
    "Look at the total number of observations in the basetable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "200ca719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a3a93",
   "metadata": {},
   "source": [
    "We cannot use the randomsplit function, because we have time series data, so we have to use another approach\n",
    "https://towardsdatascience.com/time-series-from-scratch-train-test-splits-and-evaluation-metrics-4fd654de1b37#:~:text=Train%2Ftest%20splits%20in%20time%20series%20In%20machine%20learning%2C,dataset%20for%20testing%20and%20everything%20else%20for%20training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f8ec34",
   "metadata": {},
   "source": [
    "First we look at the amount of observations that will be assigned to the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dece8543",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_train = int(basetable_df.count()*0.7)\n",
    "nr_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc5eb92",
   "metadata": {},
   "source": [
    "convert the final basetable to a pandas dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52568ef3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_emojis</th>\n",
       "      <th>avg_engagement_rate</th>\n",
       "      <th>avg_exclamation_marks</th>\n",
       "      <th>avg_followers</th>\n",
       "      <th>avg_hashtags</th>\n",
       "      <th>avg_likes</th>\n",
       "      <th>avg_mentions</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>avg_retweets</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>avg_subjectivity</th>\n",
       "      <th>avg_words</th>\n",
       "      <th>date</th>\n",
       "      <th>dependent_vegan</th>\n",
       "      <th>influencers</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428018</td>\n",
       "      <td>0.030342</td>\n",
       "      <td>0.209167</td>\n",
       "      <td>7811.137549</td>\n",
       "      <td>1.506133</td>\n",
       "      <td>9.510229</td>\n",
       "      <td>1.224661</td>\n",
       "      <td>0.112772</td>\n",
       "      <td>3.362934</td>\n",
       "      <td>0.132290</td>\n",
       "      <td>0.425252</td>\n",
       "      <td>25.956101</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.835217</td>\n",
       "      <td>0.033074</td>\n",
       "      <td>0.354991</td>\n",
       "      <td>3640.014340</td>\n",
       "      <td>6.118644</td>\n",
       "      <td>18.886054</td>\n",
       "      <td>0.565913</td>\n",
       "      <td>0.179490</td>\n",
       "      <td>10.729231</td>\n",
       "      <td>0.165516</td>\n",
       "      <td>0.415197</td>\n",
       "      <td>25.754237</td>\n",
       "      <td>2022-8-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579545</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.352273</td>\n",
       "      <td>6038.816092</td>\n",
       "      <td>6.636364</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>0.240729</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>0.191034</td>\n",
       "      <td>0.403160</td>\n",
       "      <td>24.806818</td>\n",
       "      <td>2022-6-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985651</td>\n",
       "      <td>0.080885</td>\n",
       "      <td>0.349890</td>\n",
       "      <td>6134.959732</td>\n",
       "      <td>6.079470</td>\n",
       "      <td>14.191095</td>\n",
       "      <td>0.614790</td>\n",
       "      <td>0.169584</td>\n",
       "      <td>6.136778</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>0.407482</td>\n",
       "      <td>25.415011</td>\n",
       "      <td>2022-8-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.830683</td>\n",
       "      <td>0.047927</td>\n",
       "      <td>0.423761</td>\n",
       "      <td>4375.890359</td>\n",
       "      <td>6.506080</td>\n",
       "      <td>12.462609</td>\n",
       "      <td>0.405051</td>\n",
       "      <td>0.214137</td>\n",
       "      <td>6.706806</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.430801</td>\n",
       "      <td>25.509822</td>\n",
       "      <td>2022-7-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_emojis  avg_engagement_rate  avg_exclamation_marks  avg_followers  \\\n",
       "0    0.428018             0.030342               0.209167    7811.137549   \n",
       "1    0.835217             0.033074               0.354991    3640.014340   \n",
       "2    0.579545             0.009035               0.352273    6038.816092   \n",
       "3    0.985651             0.080885               0.349890    6134.959732   \n",
       "4    0.830683             0.047927               0.423761    4375.890359   \n",
       "\n",
       "   avg_hashtags  avg_likes  avg_mentions  avg_polarity  avg_retweets  \\\n",
       "0      1.506133   9.510229      1.224661      0.112772      3.362934   \n",
       "1      6.118644  18.886054      0.565913      0.179490     10.729231   \n",
       "2      6.636364   5.222222      0.261364      0.240729      2.593750   \n",
       "3      6.079470  14.191095      0.614790      0.169584      6.136778   \n",
       "4      6.506080  12.462609      0.405051      0.214137      6.706806   \n",
       "\n",
       "   avg_sentiment  avg_subjectivity  avg_words        date  dependent_vegan  \\\n",
       "0       0.132290          0.425252  25.956101  2021-11-03              1.0   \n",
       "1       0.165516          0.415197  25.754237   2022-8-15              0.0   \n",
       "2       0.191034          0.403160  24.806818   2022-6-13              0.0   \n",
       "3       0.152711          0.407482  25.415011   2022-8-14              1.0   \n",
       "4       0.178300          0.430801  25.509822   2022-7-07              0.0   \n",
       "\n",
       "   influencers  volume  \n",
       "0          120    1549  \n",
       "1          119    1062  \n",
       "2            4      88  \n",
       "3           89     906  \n",
       "4           76    1069  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable_pd = basetable_df.toPandas()\n",
    "basetable_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca175b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f7aaa31",
   "metadata": {},
   "source": [
    "Removing date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d2c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable_pd = basetable_pd.drop(['date'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "866bcc14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_emojis</th>\n",
       "      <th>avg_engagement_rate</th>\n",
       "      <th>avg_exclamation_marks</th>\n",
       "      <th>avg_followers</th>\n",
       "      <th>avg_hashtags</th>\n",
       "      <th>avg_likes</th>\n",
       "      <th>avg_mentions</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>avg_retweets</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>avg_subjectivity</th>\n",
       "      <th>avg_words</th>\n",
       "      <th>dependent_vegan</th>\n",
       "      <th>influencers</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428018</td>\n",
       "      <td>0.030342</td>\n",
       "      <td>0.209167</td>\n",
       "      <td>7811.137549</td>\n",
       "      <td>1.506133</td>\n",
       "      <td>9.510229</td>\n",
       "      <td>1.224661</td>\n",
       "      <td>0.112772</td>\n",
       "      <td>3.362934</td>\n",
       "      <td>0.132290</td>\n",
       "      <td>0.425252</td>\n",
       "      <td>25.956101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.835217</td>\n",
       "      <td>0.033074</td>\n",
       "      <td>0.354991</td>\n",
       "      <td>3640.014340</td>\n",
       "      <td>6.118644</td>\n",
       "      <td>18.886054</td>\n",
       "      <td>0.565913</td>\n",
       "      <td>0.179490</td>\n",
       "      <td>10.729231</td>\n",
       "      <td>0.165516</td>\n",
       "      <td>0.415197</td>\n",
       "      <td>25.754237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579545</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.352273</td>\n",
       "      <td>6038.816092</td>\n",
       "      <td>6.636364</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>0.240729</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>0.191034</td>\n",
       "      <td>0.403160</td>\n",
       "      <td>24.806818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985651</td>\n",
       "      <td>0.080885</td>\n",
       "      <td>0.349890</td>\n",
       "      <td>6134.959732</td>\n",
       "      <td>6.079470</td>\n",
       "      <td>14.191095</td>\n",
       "      <td>0.614790</td>\n",
       "      <td>0.169584</td>\n",
       "      <td>6.136778</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>0.407482</td>\n",
       "      <td>25.415011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.830683</td>\n",
       "      <td>0.047927</td>\n",
       "      <td>0.423761</td>\n",
       "      <td>4375.890359</td>\n",
       "      <td>6.506080</td>\n",
       "      <td>12.462609</td>\n",
       "      <td>0.405051</td>\n",
       "      <td>0.214137</td>\n",
       "      <td>6.706806</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.430801</td>\n",
       "      <td>25.509822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.737395</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>0.386555</td>\n",
       "      <td>5702.735889</td>\n",
       "      <td>5.657563</td>\n",
       "      <td>12.082051</td>\n",
       "      <td>0.497899</td>\n",
       "      <td>0.209101</td>\n",
       "      <td>6.269592</td>\n",
       "      <td>0.169099</td>\n",
       "      <td>0.425937</td>\n",
       "      <td>24.495798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.439394</td>\n",
       "      <td>0.021345</td>\n",
       "      <td>0.209596</td>\n",
       "      <td>3704.725131</td>\n",
       "      <td>1.676768</td>\n",
       "      <td>14.878924</td>\n",
       "      <td>1.093434</td>\n",
       "      <td>0.127022</td>\n",
       "      <td>7.695122</td>\n",
       "      <td>0.126515</td>\n",
       "      <td>0.460762</td>\n",
       "      <td>29.348485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.724848</td>\n",
       "      <td>0.033227</td>\n",
       "      <td>0.320884</td>\n",
       "      <td>5130.609509</td>\n",
       "      <td>4.293445</td>\n",
       "      <td>19.236439</td>\n",
       "      <td>0.586128</td>\n",
       "      <td>0.155153</td>\n",
       "      <td>11.462567</td>\n",
       "      <td>0.149604</td>\n",
       "      <td>0.411520</td>\n",
       "      <td>25.218750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129</td>\n",
       "      <td>1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.715980</td>\n",
       "      <td>0.028071</td>\n",
       "      <td>0.391486</td>\n",
       "      <td>9470.182910</td>\n",
       "      <td>5.845778</td>\n",
       "      <td>15.801001</td>\n",
       "      <td>0.515003</td>\n",
       "      <td>0.207223</td>\n",
       "      <td>5.529293</td>\n",
       "      <td>0.154718</td>\n",
       "      <td>0.443063</td>\n",
       "      <td>25.990230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.736573</td>\n",
       "      <td>0.020365</td>\n",
       "      <td>0.363171</td>\n",
       "      <td>4784.184143</td>\n",
       "      <td>5.948849</td>\n",
       "      <td>13.678414</td>\n",
       "      <td>0.370844</td>\n",
       "      <td>0.194724</td>\n",
       "      <td>10.312000</td>\n",
       "      <td>0.161826</td>\n",
       "      <td>0.421671</td>\n",
       "      <td>25.631714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.038154</td>\n",
       "      <td>0.300840</td>\n",
       "      <td>5410.136797</td>\n",
       "      <td>6.426891</td>\n",
       "      <td>14.445614</td>\n",
       "      <td>0.348739</td>\n",
       "      <td>0.184172</td>\n",
       "      <td>6.766129</td>\n",
       "      <td>0.166143</td>\n",
       "      <td>0.424474</td>\n",
       "      <td>25.534454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.877268</td>\n",
       "      <td>0.032376</td>\n",
       "      <td>0.346852</td>\n",
       "      <td>3448.854839</td>\n",
       "      <td>5.709712</td>\n",
       "      <td>21.727431</td>\n",
       "      <td>0.378869</td>\n",
       "      <td>0.186542</td>\n",
       "      <td>7.645768</td>\n",
       "      <td>0.165664</td>\n",
       "      <td>0.408818</td>\n",
       "      <td>23.978655</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.448870</td>\n",
       "      <td>0.034540</td>\n",
       "      <td>0.217992</td>\n",
       "      <td>14339.891651</td>\n",
       "      <td>0.957831</td>\n",
       "      <td>12.666247</td>\n",
       "      <td>0.907696</td>\n",
       "      <td>0.118552</td>\n",
       "      <td>6.766776</td>\n",
       "      <td>0.136142</td>\n",
       "      <td>0.416541</td>\n",
       "      <td>23.792433</td>\n",
       "      <td>1.0</td>\n",
       "      <td>356</td>\n",
       "      <td>8537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.661578</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.370229</td>\n",
       "      <td>6531.685897</td>\n",
       "      <td>5.685751</td>\n",
       "      <td>17.173516</td>\n",
       "      <td>0.454198</td>\n",
       "      <td>0.200482</td>\n",
       "      <td>9.928854</td>\n",
       "      <td>0.169952</td>\n",
       "      <td>0.425493</td>\n",
       "      <td>24.311705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.781513</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>0.353875</td>\n",
       "      <td>8110.828922</td>\n",
       "      <td>5.839402</td>\n",
       "      <td>12.902357</td>\n",
       "      <td>0.511671</td>\n",
       "      <td>0.187239</td>\n",
       "      <td>8.153153</td>\n",
       "      <td>0.165494</td>\n",
       "      <td>0.415317</td>\n",
       "      <td>24.923436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.015643</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>14294.638889</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.235408</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>0.215417</td>\n",
       "      <td>0.419162</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.764605</td>\n",
       "      <td>0.031361</td>\n",
       "      <td>0.377148</td>\n",
       "      <td>15252.202609</td>\n",
       "      <td>5.698454</td>\n",
       "      <td>14.528037</td>\n",
       "      <td>0.631443</td>\n",
       "      <td>0.180093</td>\n",
       "      <td>5.389381</td>\n",
       "      <td>0.154671</td>\n",
       "      <td>0.419868</td>\n",
       "      <td>25.130584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93</td>\n",
       "      <td>1164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.339216</td>\n",
       "      <td>5466.722388</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>21.117647</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.192188</td>\n",
       "      <td>7.323615</td>\n",
       "      <td>0.154964</td>\n",
       "      <td>0.417697</td>\n",
       "      <td>24.140196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.041667</td>\n",
       "      <td>0.021922</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2650.416667</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.132796</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.102292</td>\n",
       "      <td>0.448499</td>\n",
       "      <td>22.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.026331</td>\n",
       "      <td>0.269167</td>\n",
       "      <td>5702.876158</td>\n",
       "      <td>5.164167</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.175879</td>\n",
       "      <td>7.754386</td>\n",
       "      <td>0.159022</td>\n",
       "      <td>0.412460</td>\n",
       "      <td>25.512500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.629578</td>\n",
       "      <td>0.022506</td>\n",
       "      <td>0.294402</td>\n",
       "      <td>3931.112587</td>\n",
       "      <td>6.593642</td>\n",
       "      <td>12.379095</td>\n",
       "      <td>0.319972</td>\n",
       "      <td>0.164717</td>\n",
       "      <td>6.871508</td>\n",
       "      <td>0.156130</td>\n",
       "      <td>0.424645</td>\n",
       "      <td>26.761576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67</td>\n",
       "      <td>1447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.741966</td>\n",
       "      <td>0.054561</td>\n",
       "      <td>0.355388</td>\n",
       "      <td>3398.007626</td>\n",
       "      <td>5.347826</td>\n",
       "      <td>21.073770</td>\n",
       "      <td>0.331758</td>\n",
       "      <td>0.169807</td>\n",
       "      <td>10.969040</td>\n",
       "      <td>0.158117</td>\n",
       "      <td>0.381186</td>\n",
       "      <td>24.463138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59</td>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.781746</td>\n",
       "      <td>0.035412</td>\n",
       "      <td>0.373016</td>\n",
       "      <td>8265.058233</td>\n",
       "      <td>5.716270</td>\n",
       "      <td>10.215488</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.191682</td>\n",
       "      <td>4.077151</td>\n",
       "      <td>0.158239</td>\n",
       "      <td>0.408103</td>\n",
       "      <td>25.006944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.506252</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>0.248568</td>\n",
       "      <td>18653.361341</td>\n",
       "      <td>1.120603</td>\n",
       "      <td>15.566715</td>\n",
       "      <td>0.841884</td>\n",
       "      <td>0.133264</td>\n",
       "      <td>7.130705</td>\n",
       "      <td>0.142071</td>\n",
       "      <td>0.403235</td>\n",
       "      <td>22.825874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>394</td>\n",
       "      <td>8557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.524968</td>\n",
       "      <td>0.031454</td>\n",
       "      <td>0.213828</td>\n",
       "      <td>4455.033592</td>\n",
       "      <td>2.290653</td>\n",
       "      <td>11.629291</td>\n",
       "      <td>0.969270</td>\n",
       "      <td>0.127508</td>\n",
       "      <td>5.819672</td>\n",
       "      <td>0.129229</td>\n",
       "      <td>0.416399</td>\n",
       "      <td>28.710627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.596211</td>\n",
       "      <td>0.017589</td>\n",
       "      <td>0.230235</td>\n",
       "      <td>12490.079043</td>\n",
       "      <td>1.136130</td>\n",
       "      <td>8.506925</td>\n",
       "      <td>1.374630</td>\n",
       "      <td>0.134489</td>\n",
       "      <td>4.268884</td>\n",
       "      <td>0.140779</td>\n",
       "      <td>0.422743</td>\n",
       "      <td>24.399969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>638</td>\n",
       "      <td>12826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.422879</td>\n",
       "      <td>0.021643</td>\n",
       "      <td>0.266067</td>\n",
       "      <td>7215.267097</td>\n",
       "      <td>3.020566</td>\n",
       "      <td>8.687943</td>\n",
       "      <td>1.037275</td>\n",
       "      <td>0.126104</td>\n",
       "      <td>2.946746</td>\n",
       "      <td>0.126188</td>\n",
       "      <td>0.420840</td>\n",
       "      <td>27.358612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.802740</td>\n",
       "      <td>0.034788</td>\n",
       "      <td>0.316438</td>\n",
       "      <td>7486.169421</td>\n",
       "      <td>5.475342</td>\n",
       "      <td>18.820399</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0.181025</td>\n",
       "      <td>8.220217</td>\n",
       "      <td>0.170226</td>\n",
       "      <td>0.402289</td>\n",
       "      <td>23.986301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.508526</td>\n",
       "      <td>0.098925</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>6823.860314</td>\n",
       "      <td>2.603638</td>\n",
       "      <td>11.879668</td>\n",
       "      <td>1.181508</td>\n",
       "      <td>0.149072</td>\n",
       "      <td>9.060543</td>\n",
       "      <td>0.144851</td>\n",
       "      <td>0.405421</td>\n",
       "      <td>24.087154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165</td>\n",
       "      <td>2639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.608655</td>\n",
       "      <td>0.025739</td>\n",
       "      <td>0.349953</td>\n",
       "      <td>4651.524543</td>\n",
       "      <td>6.095955</td>\n",
       "      <td>13.924007</td>\n",
       "      <td>0.371590</td>\n",
       "      <td>0.202521</td>\n",
       "      <td>6.321543</td>\n",
       "      <td>0.160632</td>\n",
       "      <td>0.422065</td>\n",
       "      <td>25.296331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.672251</td>\n",
       "      <td>0.022718</td>\n",
       "      <td>0.416754</td>\n",
       "      <td>4553.771277</td>\n",
       "      <td>6.537173</td>\n",
       "      <td>16.570342</td>\n",
       "      <td>0.359162</td>\n",
       "      <td>0.200613</td>\n",
       "      <td>9.892734</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0.428341</td>\n",
       "      <td>25.848168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.765122</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.321288</td>\n",
       "      <td>5549.047962</td>\n",
       "      <td>5.602514</td>\n",
       "      <td>21.210046</td>\n",
       "      <td>0.515318</td>\n",
       "      <td>0.176565</td>\n",
       "      <td>12.337696</td>\n",
       "      <td>0.163287</td>\n",
       "      <td>0.423509</td>\n",
       "      <td>24.616654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117</td>\n",
       "      <td>1273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.039369</td>\n",
       "      <td>0.327094</td>\n",
       "      <td>6990.021622</td>\n",
       "      <td>6.131907</td>\n",
       "      <td>16.301695</td>\n",
       "      <td>0.552585</td>\n",
       "      <td>0.214221</td>\n",
       "      <td>10.744027</td>\n",
       "      <td>0.176046</td>\n",
       "      <td>0.420434</td>\n",
       "      <td>23.810160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.455324</td>\n",
       "      <td>0.032850</td>\n",
       "      <td>0.179927</td>\n",
       "      <td>3147.002478</td>\n",
       "      <td>1.753978</td>\n",
       "      <td>15.093254</td>\n",
       "      <td>1.193390</td>\n",
       "      <td>0.116633</td>\n",
       "      <td>6.331288</td>\n",
       "      <td>0.122231</td>\n",
       "      <td>0.430501</td>\n",
       "      <td>28.932681</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.623836</td>\n",
       "      <td>0.023439</td>\n",
       "      <td>0.512104</td>\n",
       "      <td>8638.893816</td>\n",
       "      <td>7.021105</td>\n",
       "      <td>14.804613</td>\n",
       "      <td>0.322781</td>\n",
       "      <td>0.176932</td>\n",
       "      <td>6.004831</td>\n",
       "      <td>0.125531</td>\n",
       "      <td>0.431627</td>\n",
       "      <td>25.052762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "      <td>1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.746753</td>\n",
       "      <td>0.039252</td>\n",
       "      <td>0.402597</td>\n",
       "      <td>5915.106805</td>\n",
       "      <td>6.490724</td>\n",
       "      <td>14.806071</td>\n",
       "      <td>0.457328</td>\n",
       "      <td>0.183769</td>\n",
       "      <td>6.271768</td>\n",
       "      <td>0.156344</td>\n",
       "      <td>0.418361</td>\n",
       "      <td>25.592764</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.459607</td>\n",
       "      <td>0.044139</td>\n",
       "      <td>0.210970</td>\n",
       "      <td>10976.395727</td>\n",
       "      <td>1.063188</td>\n",
       "      <td>14.612151</td>\n",
       "      <td>1.062262</td>\n",
       "      <td>0.120329</td>\n",
       "      <td>7.331484</td>\n",
       "      <td>0.139776</td>\n",
       "      <td>0.411087</td>\n",
       "      <td>23.382423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>409</td>\n",
       "      <td>9717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.479939</td>\n",
       "      <td>0.023383</td>\n",
       "      <td>0.227964</td>\n",
       "      <td>8371.068342</td>\n",
       "      <td>0.871733</td>\n",
       "      <td>15.309024</td>\n",
       "      <td>0.951064</td>\n",
       "      <td>0.123120</td>\n",
       "      <td>9.171306</td>\n",
       "      <td>0.140332</td>\n",
       "      <td>0.407950</td>\n",
       "      <td>22.135258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.721668</td>\n",
       "      <td>0.061040</td>\n",
       "      <td>0.382593</td>\n",
       "      <td>9202.586017</td>\n",
       "      <td>5.601995</td>\n",
       "      <td>24.119335</td>\n",
       "      <td>0.442430</td>\n",
       "      <td>0.202362</td>\n",
       "      <td>12.948454</td>\n",
       "      <td>0.183788</td>\n",
       "      <td>0.439729</td>\n",
       "      <td>24.836809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.823944</td>\n",
       "      <td>0.035534</td>\n",
       "      <td>0.397887</td>\n",
       "      <td>14010.413854</td>\n",
       "      <td>6.297535</td>\n",
       "      <td>7.524528</td>\n",
       "      <td>0.491197</td>\n",
       "      <td>0.166063</td>\n",
       "      <td>4.125749</td>\n",
       "      <td>0.156213</td>\n",
       "      <td>0.395939</td>\n",
       "      <td>25.646127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.529061</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.296572</td>\n",
       "      <td>3125.231928</td>\n",
       "      <td>3.299553</td>\n",
       "      <td>16.674352</td>\n",
       "      <td>0.657228</td>\n",
       "      <td>0.148562</td>\n",
       "      <td>3.409357</td>\n",
       "      <td>0.137112</td>\n",
       "      <td>0.417647</td>\n",
       "      <td>24.830104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.029998</td>\n",
       "      <td>0.370709</td>\n",
       "      <td>5789.466513</td>\n",
       "      <td>6.415332</td>\n",
       "      <td>11.813142</td>\n",
       "      <td>0.344394</td>\n",
       "      <td>0.211240</td>\n",
       "      <td>5.503472</td>\n",
       "      <td>0.174667</td>\n",
       "      <td>0.418677</td>\n",
       "      <td>24.860412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.661745</td>\n",
       "      <td>0.014145</td>\n",
       "      <td>0.336242</td>\n",
       "      <td>9808.044898</td>\n",
       "      <td>6.839597</td>\n",
       "      <td>6.876522</td>\n",
       "      <td>0.436913</td>\n",
       "      <td>0.178518</td>\n",
       "      <td>3.410658</td>\n",
       "      <td>0.155135</td>\n",
       "      <td>0.428772</td>\n",
       "      <td>26.394631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.949780</td>\n",
       "      <td>0.028610</td>\n",
       "      <td>0.428194</td>\n",
       "      <td>7812.276937</td>\n",
       "      <td>5.610573</td>\n",
       "      <td>10.503925</td>\n",
       "      <td>0.543612</td>\n",
       "      <td>0.209414</td>\n",
       "      <td>5.383954</td>\n",
       "      <td>0.166171</td>\n",
       "      <td>0.428801</td>\n",
       "      <td>24.940969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.758376</td>\n",
       "      <td>0.036114</td>\n",
       "      <td>0.367513</td>\n",
       "      <td>4606.169908</td>\n",
       "      <td>5.792893</td>\n",
       "      <td>6.240250</td>\n",
       "      <td>0.433503</td>\n",
       "      <td>0.222961</td>\n",
       "      <td>4.034722</td>\n",
       "      <td>0.176352</td>\n",
       "      <td>0.434843</td>\n",
       "      <td>25.168528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.035018</td>\n",
       "      <td>0.326275</td>\n",
       "      <td>5098.903892</td>\n",
       "      <td>6.124706</td>\n",
       "      <td>9.859970</td>\n",
       "      <td>0.519216</td>\n",
       "      <td>0.166774</td>\n",
       "      <td>4.351893</td>\n",
       "      <td>0.167655</td>\n",
       "      <td>0.447508</td>\n",
       "      <td>26.015686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.677243</td>\n",
       "      <td>0.039509</td>\n",
       "      <td>0.299781</td>\n",
       "      <td>6887.388950</td>\n",
       "      <td>6.452954</td>\n",
       "      <td>12.096115</td>\n",
       "      <td>0.357768</td>\n",
       "      <td>0.190247</td>\n",
       "      <td>4.603604</td>\n",
       "      <td>0.160255</td>\n",
       "      <td>0.408632</td>\n",
       "      <td>24.830416</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.878128</td>\n",
       "      <td>0.027895</td>\n",
       "      <td>0.363439</td>\n",
       "      <td>5909.140814</td>\n",
       "      <td>5.797606</td>\n",
       "      <td>19.777778</td>\n",
       "      <td>0.346028</td>\n",
       "      <td>0.186397</td>\n",
       "      <td>7.990099</td>\n",
       "      <td>0.155129</td>\n",
       "      <td>0.414065</td>\n",
       "      <td>24.671382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.663333</td>\n",
       "      <td>0.028461</td>\n",
       "      <td>0.432222</td>\n",
       "      <td>5328.755079</td>\n",
       "      <td>6.051111</td>\n",
       "      <td>6.641667</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.216518</td>\n",
       "      <td>3.544444</td>\n",
       "      <td>0.173628</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.839060</td>\n",
       "      <td>0.023724</td>\n",
       "      <td>0.365280</td>\n",
       "      <td>4499.413919</td>\n",
       "      <td>7.202532</td>\n",
       "      <td>5.030568</td>\n",
       "      <td>0.368897</td>\n",
       "      <td>0.181774</td>\n",
       "      <td>2.918699</td>\n",
       "      <td>0.158537</td>\n",
       "      <td>0.404578</td>\n",
       "      <td>25.775769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    avg_emojis  avg_engagement_rate  avg_exclamation_marks  avg_followers  \\\n",
       "0     0.428018             0.030342               0.209167    7811.137549   \n",
       "1     0.835217             0.033074               0.354991    3640.014340   \n",
       "2     0.579545             0.009035               0.352273    6038.816092   \n",
       "3     0.985651             0.080885               0.349890    6134.959732   \n",
       "4     0.830683             0.047927               0.423761    4375.890359   \n",
       "5     0.737395             0.025709               0.386555    5702.735889   \n",
       "6     0.439394             0.021345               0.209596    3704.725131   \n",
       "7     0.724848             0.033227               0.320884    5130.609509   \n",
       "8     0.715980             0.028071               0.391486    9470.182910   \n",
       "9     0.736573             0.020365               0.363171    4784.184143   \n",
       "10    0.664706             0.038154               0.300840    5410.136797   \n",
       "11    0.877268             0.032376               0.346852    3448.854839   \n",
       "12    0.448870             0.034540               0.217992   14339.891651   \n",
       "13    0.661578             0.034247               0.370229    6531.685897   \n",
       "14    0.781513             0.018263               0.353875    8110.828922   \n",
       "15    1.111111             0.015643               0.305556   14294.638889   \n",
       "16    0.764605             0.031361               0.377148   15252.202609   \n",
       "17    0.783333             0.035799               0.339216    5466.722388   \n",
       "18    1.041667             0.021922               0.250000    2650.416667   \n",
       "19    0.702500             0.026331               0.269167    5702.876158   \n",
       "20    0.629578             0.022506               0.294402    3931.112587   \n",
       "21    0.741966             0.054561               0.355388    3398.007626   \n",
       "22    0.781746             0.035412               0.373016    8265.058233   \n",
       "23    0.506252             0.038237               0.248568   18653.361341   \n",
       "24    0.524968             0.031454               0.213828    4455.033592   \n",
       "25    0.596211             0.017589               0.230235   12490.079043   \n",
       "26    0.422879             0.021643               0.266067    7215.267097   \n",
       "27    0.802740             0.034788               0.316438    7486.169421   \n",
       "28    0.508526             0.098925               0.255400    6823.860314   \n",
       "29    0.608655             0.025739               0.349953    4651.524543   \n",
       "30    0.672251             0.022718               0.416754    4553.771277   \n",
       "31    0.765122             0.026500               0.321288    5549.047962   \n",
       "32    0.647059             0.039369               0.327094    6990.021622   \n",
       "33    0.455324             0.032850               0.179927    3147.002478   \n",
       "34    0.623836             0.023439               0.512104    8638.893816   \n",
       "35    0.746753             0.039252               0.402597    5915.106805   \n",
       "36    0.459607             0.044139               0.210970   10976.395727   \n",
       "37    0.479939             0.023383               0.227964    8371.068342   \n",
       "38    0.721668             0.061040               0.382593    9202.586017   \n",
       "39    0.823944             0.035534               0.397887   14010.413854   \n",
       "40    0.529061             0.025428               0.296572    3125.231928   \n",
       "41    0.657895             0.029998               0.370709    5789.466513   \n",
       "42    0.661745             0.014145               0.336242    9808.044898   \n",
       "43    0.949780             0.028610               0.428194    7812.276937   \n",
       "44    0.758376             0.036114               0.367513    4606.169908   \n",
       "45    0.737255             0.035018               0.326275    5098.903892   \n",
       "46    0.677243             0.039509               0.299781    6887.388950   \n",
       "47    0.878128             0.027895               0.363439    5909.140814   \n",
       "48    0.663333             0.028461               0.432222    5328.755079   \n",
       "49    0.839060             0.023724               0.365280    4499.413919   \n",
       "\n",
       "    avg_hashtags  avg_likes  avg_mentions  avg_polarity  avg_retweets  \\\n",
       "0       1.506133   9.510229      1.224661      0.112772      3.362934   \n",
       "1       6.118644  18.886054      0.565913      0.179490     10.729231   \n",
       "2       6.636364   5.222222      0.261364      0.240729      2.593750   \n",
       "3       6.079470  14.191095      0.614790      0.169584      6.136778   \n",
       "4       6.506080  12.462609      0.405051      0.214137      6.706806   \n",
       "5       5.657563  12.082051      0.497899      0.209101      6.269592   \n",
       "6       1.676768  14.878924      1.093434      0.127022      7.695122   \n",
       "7       4.293445  19.236439      0.586128      0.155153     11.462567   \n",
       "8       5.845778  15.801001      0.515003      0.207223      5.529293   \n",
       "9       5.948849  13.678414      0.370844      0.194724     10.312000   \n",
       "10      6.426891  14.445614      0.348739      0.184172      6.766129   \n",
       "11      5.709712  21.727431      0.378869      0.186542      7.645768   \n",
       "12      0.957831  12.666247      0.907696      0.118552      6.766776   \n",
       "13      5.685751  17.173516      0.454198      0.200482      9.928854   \n",
       "14      5.839402  12.902357      0.511671      0.187239      8.153153   \n",
       "15      6.833333   5.000000      0.777778      0.235408      3.875000   \n",
       "16      5.698454  14.528037      0.631443      0.180093      5.389381   \n",
       "17      5.833333  21.117647      0.539216      0.192188      7.323615   \n",
       "18      6.166667   1.200000      0.250000      0.132796      1.500000   \n",
       "19      5.164167  18.000000      0.606667      0.175879      7.754386   \n",
       "20      6.593642  12.379095      0.319972      0.164717      6.871508   \n",
       "21      5.347826  21.073770      0.331758      0.169807     10.969040   \n",
       "22      5.716270  10.215488      0.416667      0.191682      4.077151   \n",
       "23      1.120603  15.566715      0.841884      0.133264      7.130705   \n",
       "24      2.290653  11.629291      0.969270      0.127508      5.819672   \n",
       "25      1.136130   8.506925      1.374630      0.134489      4.268884   \n",
       "26      3.020566   8.687943      1.037275      0.126104      2.946746   \n",
       "27      5.475342  18.820399      0.397260      0.181025      8.220217   \n",
       "28      2.603638  11.879668      1.181508      0.149072      9.060543   \n",
       "29      6.095955  13.924007      0.371590      0.202521      6.321543   \n",
       "30      6.537173  16.570342      0.359162      0.200613      9.892734   \n",
       "31      5.602514  21.210046      0.515318      0.176565     12.337696   \n",
       "32      6.131907  16.301695      0.552585      0.214221     10.744027   \n",
       "33      1.753978  15.093254      1.193390      0.116633      6.331288   \n",
       "34      7.021105  14.804613      0.322781      0.176932      6.004831   \n",
       "35      6.490724  14.806071      0.457328      0.183769      6.271768   \n",
       "36      1.063188  14.612151      1.062262      0.120329      7.331484   \n",
       "37      0.871733  15.309024      0.951064      0.123120      9.171306   \n",
       "38      5.601995  24.119335      0.442430      0.202362     12.948454   \n",
       "39      6.297535   7.524528      0.491197      0.166063      4.125749   \n",
       "40      3.299553  16.674352      0.657228      0.148562      3.409357   \n",
       "41      6.415332  11.813142      0.344394      0.211240      5.503472   \n",
       "42      6.839597   6.876522      0.436913      0.178518      3.410658   \n",
       "43      5.610573  10.503925      0.543612      0.209414      5.383954   \n",
       "44      5.792893   6.240250      0.433503      0.222961      4.034722   \n",
       "45      6.124706   9.859970      0.519216      0.166774      4.351893   \n",
       "46      6.452954  12.096115      0.357768      0.190247      4.603604   \n",
       "47      5.797606  19.777778      0.346028      0.186397      7.990099   \n",
       "48      6.051111   6.641667      0.433333      0.216518      3.544444   \n",
       "49      7.202532   5.030568      0.368897      0.181774      2.918699   \n",
       "\n",
       "    avg_sentiment  avg_subjectivity  avg_words  dependent_vegan  influencers  \\\n",
       "0        0.132290          0.425252  25.956101              1.0          120   \n",
       "1        0.165516          0.415197  25.754237              0.0          119   \n",
       "2        0.191034          0.403160  24.806818              0.0            4   \n",
       "3        0.152711          0.407482  25.415011              1.0           89   \n",
       "4        0.178300          0.430801  25.509822              0.0           76   \n",
       "5        0.169099          0.425937  24.495798              1.0           78   \n",
       "6        0.126515          0.460762  29.348485              0.0           32   \n",
       "7        0.149604          0.411520  25.218750              1.0          129   \n",
       "8        0.154718          0.443063  25.990230              0.0           93   \n",
       "9        0.161826          0.421671  25.631714              1.0           40   \n",
       "10       0.166143          0.424474  25.534454              1.0           81   \n",
       "11       0.165664          0.408818  23.978655              1.0          100   \n",
       "12       0.136142          0.416541  23.792433              1.0          356   \n",
       "13       0.169952          0.425493  24.311705              1.0           57   \n",
       "14       0.165494          0.415317  24.923436              1.0           90   \n",
       "15       0.215417          0.419162  23.666667              0.0            2   \n",
       "16       0.154671          0.419868  25.130584              0.0           93   \n",
       "17       0.154964          0.417697  24.140196              1.0           79   \n",
       "18       0.102292          0.448499  22.166667              1.0            1   \n",
       "19       0.159022          0.412460  25.512500              1.0          107   \n",
       "20       0.156130          0.424645  26.761576              0.0           67   \n",
       "21       0.158117          0.381186  24.463138              0.0           59   \n",
       "22       0.158239          0.408103  25.006944              0.0           73   \n",
       "23       0.142071          0.403235  22.825874              1.0          394   \n",
       "24       0.129229          0.416399  28.710627              0.0           57   \n",
       "25       0.140779          0.422743  24.399969              0.0          638   \n",
       "26       0.126188          0.420840  27.358612              0.0           62   \n",
       "27       0.170226          0.402289  23.986301              0.0           88   \n",
       "28       0.144851          0.405421  24.087154              1.0          165   \n",
       "29       0.160632          0.422065  25.296331              0.0           78   \n",
       "30       0.165435          0.428341  25.848168              0.0           85   \n",
       "31       0.163287          0.423509  24.616654              0.0          117   \n",
       "32       0.176046          0.420434  23.810160              0.0           74   \n",
       "33       0.122231          0.430501  28.932681              1.0           63   \n",
       "34       0.125531          0.431627  25.052762              1.0           88   \n",
       "35       0.156344          0.418361  25.592764              1.0           82   \n",
       "36       0.139776          0.411087  23.382423              1.0          409   \n",
       "37       0.140332          0.407950  22.135258              1.0          128   \n",
       "38       0.183788          0.439729  24.836809              1.0          114   \n",
       "39       0.156213          0.395939  25.646127              1.0           36   \n",
       "40       0.137112          0.417647  24.830104              1.0           56   \n",
       "41       0.174667          0.418677  24.860412              1.0           87   \n",
       "42       0.155135          0.428772  26.394631              0.0           71   \n",
       "43       0.166171          0.428801  24.940969              0.0           82   \n",
       "44       0.176352          0.434843  25.168528              0.0           83   \n",
       "45       0.167655          0.447508  26.015686              1.0          101   \n",
       "46       0.160255          0.408632  24.830416              1.0           79   \n",
       "47       0.155129          0.414065  24.671382              0.0           82   \n",
       "48       0.173628          0.426471  26.000000              0.0           92   \n",
       "49       0.158537          0.404578  25.775769              1.0           35   \n",
       "\n",
       "    volume  \n",
       "0     1549  \n",
       "1     1062  \n",
       "2       88  \n",
       "3      906  \n",
       "4     1069  \n",
       "5      952  \n",
       "6      396  \n",
       "7     1312  \n",
       "8     1433  \n",
       "9      391  \n",
       "10    1190  \n",
       "11     937  \n",
       "12    8537  \n",
       "13     786  \n",
       "14    1071  \n",
       "15      36  \n",
       "16    1164  \n",
       "17    1020  \n",
       "18      24  \n",
       "19    1200  \n",
       "20    1447  \n",
       "21    1058  \n",
       "22    1008  \n",
       "23    8557  \n",
       "24     781  \n",
       "25   12826  \n",
       "26     778  \n",
       "27     730  \n",
       "28    2639  \n",
       "29    1063  \n",
       "30     955  \n",
       "31    1273  \n",
       "32    1122  \n",
       "33     817  \n",
       "34    1611  \n",
       "35    1078  \n",
       "36    9717  \n",
       "37    3290  \n",
       "38    1103  \n",
       "39     568  \n",
       "40     671  \n",
       "41     874  \n",
       "42    1490  \n",
       "43    1135  \n",
       "44     985  \n",
       "45    1275  \n",
       "46     914  \n",
       "47     919  \n",
       "48     900  \n",
       "49     553  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable_pd.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eaf526",
   "metadata": {},
   "source": [
    "Split the dataframe into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be927ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd = basetable_pd.iloc[:nr_train,:]\n",
    "test_pd = basetable_pd.iloc[nr_train:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a577dee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_emojis</th>\n",
       "      <th>avg_engagement_rate</th>\n",
       "      <th>avg_exclamation_marks</th>\n",
       "      <th>avg_followers</th>\n",
       "      <th>avg_hashtags</th>\n",
       "      <th>avg_likes</th>\n",
       "      <th>avg_mentions</th>\n",
       "      <th>avg_polarity</th>\n",
       "      <th>avg_retweets</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>avg_subjectivity</th>\n",
       "      <th>avg_words</th>\n",
       "      <th>dependent_vegan</th>\n",
       "      <th>influencers</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428018</td>\n",
       "      <td>0.030342</td>\n",
       "      <td>0.209167</td>\n",
       "      <td>7811.137549</td>\n",
       "      <td>1.506133</td>\n",
       "      <td>9.510229</td>\n",
       "      <td>1.224661</td>\n",
       "      <td>0.112772</td>\n",
       "      <td>3.362934</td>\n",
       "      <td>0.132290</td>\n",
       "      <td>0.425252</td>\n",
       "      <td>25.956101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.835217</td>\n",
       "      <td>0.033074</td>\n",
       "      <td>0.354991</td>\n",
       "      <td>3640.014340</td>\n",
       "      <td>6.118644</td>\n",
       "      <td>18.886054</td>\n",
       "      <td>0.565913</td>\n",
       "      <td>0.179490</td>\n",
       "      <td>10.729231</td>\n",
       "      <td>0.165516</td>\n",
       "      <td>0.415197</td>\n",
       "      <td>25.754237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579545</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.352273</td>\n",
       "      <td>6038.816092</td>\n",
       "      <td>6.636364</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>0.240729</td>\n",
       "      <td>2.593750</td>\n",
       "      <td>0.191034</td>\n",
       "      <td>0.403160</td>\n",
       "      <td>24.806818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985651</td>\n",
       "      <td>0.080885</td>\n",
       "      <td>0.349890</td>\n",
       "      <td>6134.959732</td>\n",
       "      <td>6.079470</td>\n",
       "      <td>14.191095</td>\n",
       "      <td>0.614790</td>\n",
       "      <td>0.169584</td>\n",
       "      <td>6.136778</td>\n",
       "      <td>0.152711</td>\n",
       "      <td>0.407482</td>\n",
       "      <td>25.415011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89</td>\n",
       "      <td>906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.830683</td>\n",
       "      <td>0.047927</td>\n",
       "      <td>0.423761</td>\n",
       "      <td>4375.890359</td>\n",
       "      <td>6.506080</td>\n",
       "      <td>12.462609</td>\n",
       "      <td>0.405051</td>\n",
       "      <td>0.214137</td>\n",
       "      <td>6.706806</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.430801</td>\n",
       "      <td>25.509822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_emojis  avg_engagement_rate  avg_exclamation_marks  avg_followers  \\\n",
       "0    0.428018             0.030342               0.209167    7811.137549   \n",
       "1    0.835217             0.033074               0.354991    3640.014340   \n",
       "2    0.579545             0.009035               0.352273    6038.816092   \n",
       "3    0.985651             0.080885               0.349890    6134.959732   \n",
       "4    0.830683             0.047927               0.423761    4375.890359   \n",
       "\n",
       "   avg_hashtags  avg_likes  avg_mentions  avg_polarity  avg_retweets  \\\n",
       "0      1.506133   9.510229      1.224661      0.112772      3.362934   \n",
       "1      6.118644  18.886054      0.565913      0.179490     10.729231   \n",
       "2      6.636364   5.222222      0.261364      0.240729      2.593750   \n",
       "3      6.079470  14.191095      0.614790      0.169584      6.136778   \n",
       "4      6.506080  12.462609      0.405051      0.214137      6.706806   \n",
       "\n",
       "   avg_sentiment  avg_subjectivity  avg_words  dependent_vegan  influencers  \\\n",
       "0       0.132290          0.425252  25.956101              1.0          120   \n",
       "1       0.165516          0.415197  25.754237              0.0          119   \n",
       "2       0.191034          0.403160  24.806818              0.0            4   \n",
       "3       0.152711          0.407482  25.415011              1.0           89   \n",
       "4       0.178300          0.430801  25.509822              0.0           76   \n",
       "\n",
       "   volume  \n",
       "0    1549  \n",
       "1    1062  \n",
       "2      88  \n",
       "3     906  \n",
       "4    1069  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfc0c6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable_pd['dependent_vegan'].isnull().values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe19a50f",
   "metadata": {},
   "source": [
    "Convert the pandas dataframe back to a spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65c37906",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o42.legacyInferArrayTypeFromFirstElement. Trace:\npy4j.Py4JException: Method legacyInferArrayTypeFromFirstElement([]) does not exist\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\r\n\tat py4j.Gateway.invoke(Gateway.java:274)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m train\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mC:\\Program Files\\Spark\\spark-3.3.1-bin-hadoop3\\python\\pyspark\\sql\\session.py:1161\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m   1157\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39mcolumn_names)\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[1;32m-> 1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSparkSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dataframe(\n\u001b[0;32m   1165\u001b[0m     data, schema, samplingRatio, verifySchema  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m )\n",
      "File \u001b[1;32mC:\\Program Files\\Spark\\spark-3.3.1-bin-hadoop3\\python\\pyspark\\sql\\pandas\\conversion.py:437\u001b[0m, in \u001b[0;36mSparkConversionMixin.createDataFrame\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    436\u001b[0m converted_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_from_pandas(data, schema, timezone)\n\u001b[1;32m--> 437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Spark\\spark-3.3.1-bin-hadoop3\\python\\pyspark\\sql\\session.py:1206\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromRDD(data\u001b[38;5;241m.\u001b[39mmap(prepare), schema, samplingRatio)\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1206\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromLocal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mtoJavaArray(rdd\u001b[38;5;241m.\u001b[39m_to_java_object_rdd())\n",
      "File \u001b[1;32mC:\\Program Files\\Spark\\spark-3.3.1-bin-hadoop3\\python\\pyspark\\sql\\session.py:853\u001b[0m, in \u001b[0;36mSparkSession._createFromLocal\u001b[1;34m(self, data, schema)\u001b[0m\n\u001b[0;32m    850\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 853\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inferSchemaFromList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m     converter \u001b[38;5;241m=\u001b[39m _create_converter(struct)\n\u001b[0;32m    855\u001b[0m     tupled_data: Iterable[Tuple] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(converter, data)\n",
      "File \u001b[1;32mC:\\Program Files\\Spark\\spark-3.3.1-bin-hadoop3\\python\\pyspark\\sql\\session.py:725\u001b[0m, in \u001b[0;36mSparkSession._inferSchemaFromList\u001b[1;34m(self, data, names)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan not infer schema from empty dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    724\u001b[0m infer_dict_as_struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf\u001b[38;5;241m.\u001b[39minferDictAsStruct()\n\u001b[1;32m--> 725\u001b[0m infer_array_from_first_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacyInferArrayTypeFromFirstElement\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m prefer_timestamp_ntz \u001b[38;5;241m=\u001b[39m is_timestamp_ntz_preferred()\n\u001b[0;32m    727\u001b[0m schema \u001b[38;5;241m=\u001b[39m reduce(\n\u001b[0;32m    728\u001b[0m     _merge_type,\n\u001b[0;32m    729\u001b[0m     (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    738\u001b[0m     ),\n\u001b[0;32m    739\u001b[0m )\n",
      "File \u001b[1;32mC:\\Program Files\\Spark\\spark-3.3.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32mC:\\Program Files\\Spark\\spark-3.3.1-bin-hadoop3\\python\\pyspark\\sql\\utils.py:199\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 199\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    201\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32mC:\\Program Files\\Spark\\spark-3.3.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.5-src.zip\\py4j\\protocol.py:330\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n",
      "\u001b[1;31mPy4JError\u001b[0m: An error occurred while calling o42.legacyInferArrayTypeFromFirstElement. Trace:\npy4j.Py4JException: Method legacyInferArrayTypeFromFirstElement([]) does not exist\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\r\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\r\n\tat py4j.Gateway.invoke(Gateway.java:274)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\n\n"
     ]
    }
   ],
   "source": [
    "train = spark.createDataFrame(train_pd)\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56110f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = spark.createDataFrame(test_pd)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690b548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get number in observations in each set\n",
    "print(\"Number of observations train: %s\" %train.count())\n",
    "print(\"Number of observations test: %s\" %test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2dfd6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get distribution of dependent variable within each set\n",
    "train.groupBy(\"dependent_vegan\").count().show()\n",
    "test.groupBy(\"dependent_vegan\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ee4e0a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241m.\u001b[39mna\u001b[38;5;241m.\u001b[39mdrop()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train = train.na.drop()\n",
    "test = test.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f926f",
   "metadata": {},
   "source": [
    "# 6. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e7ec9",
   "metadata": {},
   "source": [
    "## 6.1 Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac02cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, Word2Vec\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, GBTClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376476db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define indexer (IDX)\n",
    "IDX = StringIndexer(inputCol=\"dependent_vegan\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9873338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all the numeric features\n",
    "numFeatureCols = [\"volume\", \"avg_likes\", \"avg_retweets\", \"avg_engagement_rate\", \"avg_followers\", \"avg_emojis\", \"avg_words\", \"avg_hashtags\", \"avg_mentions\", \"avg_exclamation_marks\", \"avg_sentiment\"]\n",
    "\n",
    "# define vector assembler\n",
    "VA_num = VectorAssembler(inputCols=numFeatureCols, outputCol=\"numeric_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standard scaler (SS)\n",
    "SS = StandardScaler(inputCol=\"numeric_features\", outputCol=\"scaled_numeric_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for random forest we don't scale the features \n",
    "VA_RF = VectorAssembler(inputCols=[\"volume\", \"avg_likes\", \"avg_retweets\", \"avg_engagement_rate\", \"avg_followers\", \"avg_emojis\", \"avg_words\", \"avg_hashtags\", \"avg_mentions\", \"avg_exclamation_marks\", \"avg_sentiment\", \"avg_polarity\", \"avg_subjectivity\"], outputCol=\"featuresrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a75d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vector assembler (VA_all)\n",
    "VA_all = VectorAssembler(inputCols=[\"scaled_numeric_features\", \"avg_polarity\", \"avg_subjectivity\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d02332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define logistic regression model\n",
    "LR = LogisticRegression(featuresCol = \"features\", labelCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b20a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define decision tree model\n",
    "DT = DecisionTreeClassifier(featuresCol = \"features\", labelCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0854b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define decision tree model\n",
    "GBT = GBTClassifier(featuresCol = \"features\", labelCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random forest model\n",
    "RF = RandomForestClassifier(featuresCol = \"featuresrf\", labelCol = \"label\", numTrees= 200, featureSubsetStrategy= 'all', maxDepth= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad3b110",
   "metadata": {},
   "source": [
    "## 6.2 Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline model and fit on training data\n",
    "LR_pipeline = Pipeline().setStages([IDX, VA_num, SS, VA_all, LR]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbdc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on test set\n",
    "LR_preds = LR_pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline model and fit on training data\n",
    "DT_pipeline = Pipeline().setStages([IDX, VA_num, SS, VA_all, DT]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on test set\n",
    "DT_preds = DT_pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline model and fit on training data\n",
    "GBT_pipeline = Pipeline().setStages([IDX, VA_num, SS, VA_all, GBT]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb63eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on test set\n",
    "GBT_preds = GBT_pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d68fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline model and fit on training data\n",
    "RF_pipeline = Pipeline().setStages([IDX, VA_RF, RF]).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on test set\n",
    "RF_preds = RF_pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf5b92",
   "metadata": {},
   "source": [
    "# 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05200a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluator (for AUC)\n",
    "evaluator_auc = BinaryClassificationEvaluator()\n",
    "\n",
    "# define evaluator (for other metrics)\n",
    "evaluator_mc = MulticlassClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff360e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics for LR model\n",
    "lr_f1 = evaluator_mc.evaluate(LR_preds, {evaluator_mc.metricName: \"f1\"})\n",
    "lr_accuracy = evaluator_mc.evaluate(LR_preds, {evaluator_mc.metricName: \"accuracy\"})\n",
    "lr_recall = evaluator_mc.evaluate(LR_preds, {evaluator_mc.metricName: \"recallByLabel\"})\n",
    "lr_auc = evaluator_auc.evaluate(LR_preds, {evaluator_auc.metricName: 'areaUnderROC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics for DT model\n",
    "dt_f1 = evaluator_mc.evaluate(DT_preds, {evaluator_mc.metricName: \"f1\"})\n",
    "dt_accuracy = evaluator_mc.evaluate(DT_preds, {evaluator_mc.metricName: \"accuracy\"})\n",
    "dt_recall = evaluator_mc.evaluate(DT_preds, {evaluator_mc.metricName: \"recallByLabel\"})\n",
    "dt_auc = evaluator_auc.evaluate(DT_preds, {evaluator_auc.metricName: 'areaUnderROC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31356358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics for GBT model\n",
    "gbt_f1 = evaluator_mc.evaluate(GBT_preds, {evaluator_mc.metricName: \"f1\"})\n",
    "gbt_accuracy = evaluator_mc.evaluate(GBT_preds, {evaluator_mc.metricName: \"accuracy\"})\n",
    "gbt_recall = evaluator_mc.evaluate(GBT_preds, {evaluator_mc.metricName: \"recallByLabel\"})\n",
    "gbt_auc = evaluator_auc.evaluate(GBT_preds, {evaluator_auc.metricName: 'areaUnderROC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2465cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metrics for RF model\n",
    "rf_f1 = evaluator_mc.evaluate(RF_preds, {evaluator_mc.metricName: \"f1\"})\n",
    "rf_accuracy = evaluator_mc.evaluate(RF_preds, {evaluator_mc.metricName: \"accuracy\"})\n",
    "rf_recall = evaluator_mc.evaluate(RF_preds, {evaluator_mc.metricName: \"recallByLabel\"})\n",
    "rf_auc = evaluator_auc.evaluate(RF_preds, {evaluator_auc.metricName: 'areaUnderROC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931affdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check which of both algorithms is the best:\n",
    "print(\"LOGISTIC REGRESSION:\")\n",
    "print('  F1       : %g' % lr_f1)\n",
    "print('  ACCURACY : %g' % lr_accuracy)\n",
    "print('  RECALL   : %g' % lr_recall)\n",
    "print('  AUC      : %g' % lr_auc)\n",
    "print(\"------------------\")\n",
    "print(\"SINGLE DECISION TREE:\")\n",
    "print('  F1       : %g' % dt_f1)\n",
    "print('  ACCURACY : %g' % dt_accuracy)\n",
    "print('  RECALL   : %g' % dt_recall)\n",
    "print('  AUC      : %g' % dt_auc)\n",
    "print(\"------------------\")\n",
    "print(\"GRADIENT-BOOSTED TREES:\")\n",
    "print('  F1       : %g' % gbt_f1)\n",
    "print('  ACCURACY : %g' % gbt_accuracy)\n",
    "print('  RECALL   : %g' % gbt_recall)\n",
    "print('  AUC      : %g' % gbt_auc)\n",
    "print(\"------------------\")\n",
    "print(\"RANDOM FOREST:\")\n",
    "print('  F1       : %g' % rf_f1)\n",
    "print('  ACCURACY : %g' % rf_accuracy)\n",
    "print('  RECALL   : %g' % rf_recall)\n",
    "print('  AUC      : %g' % rf_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8b950f",
   "metadata": {},
   "source": [
    "# 8 Plot model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f353ef3f",
   "metadata": {},
   "source": [
    "## 8.1 Confusion Matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db71d0d",
   "metadata": {},
   "source": [
    "We plot the confussion matrix for the model with the highest AUC, this is the random forest model with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# get predictions and labels\n",
    "preds_and_labels = RF_preds.select(['prediction','label']) \\\n",
    "                                  .withColumn('label', F.col('label').cast(FloatType())) \\\n",
    "                                  .orderBy('prediction') \\\n",
    "                                  .toPandas()\n",
    "\n",
    "# get confusion matrix\n",
    "cm = confusion_matrix(preds_and_labels[\"label\"], preds_and_labels[\"prediction\"], labels=[0, 1])\n",
    "# get confusion matrix figure\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "# plot figure\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5d4ee",
   "metadata": {},
   "source": [
    "Calculate sensitivity and specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0269b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, recall_score\n",
    "recall_sensitivity = metrics.recall_score(preds_and_labels[\"label\"], preds_and_labels[\"prediction\"], pos_label=1)\n",
    "recall_specificity = metrics.recall_score(preds_and_labels[\"label\"], preds_and_labels[\"prediction\"], pos_label=0)\n",
    "recall_sensitivity, recall_specificity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19aacb",
   "metadata": {},
   "source": [
    "## 8.2 Model interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1021b49",
   "metadata": {},
   "source": [
    "We plot the future importance for the model with the highest AUC, this is the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb064b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect feature importance\n",
    "feature_importance = RF_pipeline.stages[-1].featureImportances.toArray()\n",
    "# define all the features\n",
    "all_feature_names = numFeatureCols + [\"avg_polarity\", \"avg_subjectivity\"] \n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(x=range(len(feature_importance)), height=feature_importance)\n",
    "plt.xticks(range(len(feature_importance)), all_feature_names, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482fc250",
   "metadata": {},
   "source": [
    "## 8.3 ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e3ece0",
   "metadata": {},
   "source": [
    "We will plot the ROC curve for the model with the highest AUC, this is the random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba58f99",
   "metadata": {},
   "source": [
    "We will use plotty to plot the ROC curve, so we will have to perform some data type transformations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the rf predictions to a pandas dataframe\n",
    "RF_preds_pd = RF_preds.toPandas()\n",
    "RF_preds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a function that will select the probabilities for value 1\n",
    "def select1(column):\n",
    "    one = column[1]\n",
    "    return one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de45eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we apply this function to our probabilities \n",
    "Yscore = RF_preds_pd['probability'].apply(lambda x: select1(x)).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yscore contains the probabilities of our predictions to be 1\n",
    "Yscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yscore is of the correct type to perform the plot \n",
    "type(Yscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f923ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is the real value of our dependent\n",
    "Y = test.select('dependent_vegan').toPandas()\n",
    "Y = Y['dependent_vegan'].to_numpy()\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703699ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yscore is of the correct type to perform the plot \n",
    "type(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the roc_curve function to predict the false-positive, true-positive rate and thresholds based on the Y an Y score\n",
    "fpr, tpr, thresholds = roc_curve(Y, Yscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cfa304",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(\n",
    "    x=fpr, y=tpr,\n",
    "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
    "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "    width=700, height=500\n",
    ")\n",
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_xaxes(constrain='domain')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38d354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e35d98e8198887147a5837b6820e4bf8d41831f6222e06e86b8679b6549872f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
