{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5a9018",
   "metadata": {},
   "source": [
    "# Initialize pyspark environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07de0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "# initialize findspark with spark directory\n",
    "\n",
    "#ALWAYS HAVE TO BE CHANGED \n",
    "#path = \"/Users/konstantinlazarov/Desktop/Big_Data/PySpark/Week_5/spark\"\n",
    "path = \"/Users/Artur/spark\"\n",
    "findspark.init(path) \n",
    "\n",
    "# import pyspark\n",
    "import pyspark\n",
    "# create spark context\n",
    "sc = pyspark.SparkContext()\n",
    "# create spark session \n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c8fb25",
   "metadata": {},
   "source": [
    "# Import necessary packages and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0a568",
   "metadata": {},
   "source": [
    "#### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31aab156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os \n",
    "import pickle\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "import pytz\n",
    "import emojis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ast\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "import tweepy\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "from pandas.tseries.holiday import nearest_workday, \\\n",
    "    AbstractHolidayCalendar, Holiday, \\\n",
    "    USMartinLutherKingJr, USPresidentsDay, GoodFriday, \\\n",
    "    USMemorialDay, USLaborDay, USThanksgivingDay\n",
    "from datetime import date\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab846c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc724f3b",
   "metadata": {},
   "source": [
    "#### Import the twitter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc176e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1827680"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_brands = [\"healthyfood\",\n",
    "               \"healthylifestyle\",\n",
    "               \"vegan\",\n",
    "               \"keto\",\n",
    "               \"ketodiet\",\n",
    "               \"ketolifestyle\",\n",
    "               \"veganism\",\n",
    "               \"vegetarian\"]\n",
    "from re import search\n",
    "\n",
    "\n",
    "\n",
    "data_dir = \".././../data/Topic/\"\n",
    "tweet_files = [os.path.join(data_dir, obs) for obs in os.listdir(data_dir)]\n",
    "\n",
    "\n",
    "\n",
    "files_brand = [file for file in tweet_files if (file.find(list_brands[2]) != -1)]\n",
    "files_brand               \n",
    "               \n",
    "df_json = spark.read.option(\"multiline\",\"true\").json(files_brand)  \n",
    "df_json.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6607122",
   "metadata": {},
   "source": [
    "# Predict the engagement rate of a tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24f7dff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "138114a9",
   "metadata": {},
   "source": [
    "## 1. Goal of our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db6ca9",
   "metadata": {},
   "source": [
    "In this notebook, we are going to predict the engagement rate of tweets. Further, it will be interesting to see the driving factors behind the engagement rate. This can be valuable information when creating an own social media brand or when you want to increase the reach of your tweets.\n",
    "\n",
    "We start by creating a basetable for this model.\n",
    "\n",
    "First, we start by defining our dependent variable. The engagement rate has already been discussed in the data exploration section. We will use the same definition in order to create a model to predict the engagement rate. Below, we repeat this definition:\n",
    "\n",
    "Engagement on Twitter is measured by the number of retweets, follows, replies, favorites, and other peopleâ€™s reactions to your tweets, including the clicks on the links and hashtags in those tweets. Your Twitter engagement rate is your engagement figure divided by the number of impressions on the tweet.\n",
    "\n",
    "In order to predict the engagement of a tweet, we will use the following variables:\n",
    "\n",
    "\n",
    "    1) number of words\n",
    "    2) number of hashtags\n",
    "    3) number of tags\n",
    "    4) number of emojis\n",
    "    5) the month\n",
    "    6) day of the month\n",
    "    7) day of the week\n",
    "    8) hour of the day\n",
    "    9) the language\n",
    "    10) tweeted by an influencer or not\n",
    "    11) tweeted quote\n",
    "    13) presence of a symbol\n",
    "    14) Indicator if a mention to another user was made\n",
    "    15) The media type present\n",
    "    16) The number of text characters in the tweet\n",
    "\n",
    "\n",
    "The goal of our model is not only to predict the engagement rate, but look at the underlying drivers of the engagement rate. This way, we aim to optimize our engagement rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f6d87",
   "metadata": {},
   "source": [
    "# 2. Basetable creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626a4dae",
   "metadata": {},
   "source": [
    "We start by selecting all the variables that we will need in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2a272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the interesting variables\n",
    "basetable_engr = df_json.select(F.col('created_at').alias('tweet_created'), \\\n",
    "                                   F.col('entities.symbols').alias('symbols'), \\\n",
    "                                   F.col('display_text_range').alias('text_range'), \\\n",
    "                                   F.col('extended_entities.media.type').alias('media_type'), \\\n",
    "                                   F.col('favorite_count'), \\\n",
    "                                   F.col('full_text'), \\\n",
    "                                   F.col('is_quote_status').alias('quoted'), \\\n",
    "                                   F.col('lang').alias('language'), \\\n",
    "                                   F.col('retweet_count'),\\\n",
    "                                   F.col('user.created_at').alias('user_created'), \\\n",
    "                                   F.col('user.followers_count').alias('user_followers'), \\\n",
    "                                   F.col('user.friends_count').alias('user_following'), \\\n",
    "                                   F.col('user.verified').alias('user_verified'), \\\n",
    "                                   F.col(\"user.screen_name\"), \\\n",
    "                                   F.col('user.statuses_count').alias('nr_tweets_by_user'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e68bf81",
   "metadata": {},
   "source": [
    "## 2.1 Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66328767",
   "metadata": {},
   "source": [
    "### 2.1.1 Check Time Period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e176623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developer.twitter.com/en/docs/twitter-ads-api/timezones\n",
    "# function to convert Twitter date string format\n",
    "def getDate(date):\n",
    "    if date is not None:\n",
    "        return str(datetime.datetime.strptime(date,'%a %b %d %H:%M:%S +0000 %Y').replace(tzinfo=pytz.UTC).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# UDF declaration\n",
    "date_udf = F.udf(getDate, StringType())\n",
    "\n",
    "# apply udf\n",
    "basetable_engr = basetable_engr.withColumn('tweet_created', F.to_utc_timestamp(date_udf(\"tweet_created\"), \"UTC\"))\n",
    "basetable_engr = basetable_engr.withColumn('user_created', F.to_utc_timestamp(date_udf(\"user_created\"), \"UTC\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade772d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates and retweets \n",
    "basetable_engr = basetable_engr.filter(~F.col(\"full_text\").startswith(\"RT\"))\\\n",
    "                        .drop_duplicates()\n",
    "\n",
    "#sorting such when dropping later we only keep the most recent post \n",
    "basetable_engr = basetable_engr.sort(\"tweet_created\", ascending=False)\n",
    "\n",
    "#removing spam accounts \n",
    "basetable_engr = basetable_engr.drop_duplicates([\"full_text\", \"screen_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4166fe",
   "metadata": {},
   "source": [
    "## 2.2 Create the dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c49b00",
   "metadata": {},
   "source": [
    "AAN TE PASSEN\n",
    "\n",
    "Repeat definition: \n",
    "Engagement on Twitter is measured by the number of retweets, follows, replies, favorites, and other peopleâ€™s reactions to your tweets, including the clicks on the links and hashtags in those tweets. Your Twitter engagement rate is your engagement figure divided by the number of impressions on the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3843d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            eng_rate|\n",
      "+--------------------+\n",
      "|0.001179245283018...|\n",
      "|0.003097040605643...|\n",
      "|0.027937551355792935|\n",
      "|                 0.0|\n",
      "|                 0.0|\n",
      "|                 0.0|\n",
      "|                 0.0|\n",
      "|5.963313694153567E-5|\n",
      "|                 0.0|\n",
      "|0.004761904761904762|\n",
      "|                 0.0|\n",
      "|2.448280083241523E-4|\n",
      "|1.958863858961802E-4|\n",
      "|0.043859649122807015|\n",
      "| 0.03837118245888802|\n",
      "| 0.04980842911877394|\n",
      "|0.001669449081803005|\n",
      "|                 0.0|\n",
      "|0.003231017770597...|\n",
      "|  0.0273224043715847|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add engagement rate to the dataframe\n",
    "basetable_engr = basetable_engr.withColumn('eng_rate', ((basetable_engr['favorite_count'] + basetable_engr['retweet_count'])/basetable_engr['user_followers']))\n",
    "basetable_engr.select(F.col('eng_rate')).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b4e5df",
   "metadata": {},
   "source": [
    "### 2.3 Text cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d10a5db",
   "metadata": {},
   "source": [
    "Now that we have created the dependent variable, we will clean the text of the tweets. Then, the cleaned tokenized text can now be used to create some new features. Besides, we also use some create some new features out of other variables. For some, we first define the necessary functions. Features created:\n",
    "\n",
    "    1) number of words\n",
    "    2) number of hashtags\n",
    "    3) number of tags\n",
    "    4) number of emojis\n",
    "    5) get the number of exclamation marks\n",
    "    6) the month\n",
    "    7) day of the month\n",
    "    8) day of the week\n",
    "    9) hour of the day\n",
    "    10) The number of upper case words\n",
    "    11) tweeted quote\n",
    "    12) presence of a symbol\n",
    "    13) The age of the account\n",
    "    14) The number of media elements\n",
    "    15) The media type present\n",
    "    16) The number of text characters in the tweet\n",
    "    17) Indicator if the account is verified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fedbf6",
   "metadata": {},
   "source": [
    "First, define a function to clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b77e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define puncutation and stopwords\n",
    "PUNCTUATION = [char for char in punctuation if char not in [\"!\", \"@\", \"#\"]]\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "NUMBERS = '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab5627e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to remove punctuation\n",
    "def remove_punct(text):\n",
    "    ## Remove punctuation\n",
    "    text = \"\".join([char for char in text if char not in PUNCTUATION])\n",
    "    return(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "078f7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to tokenize the text and remove the stopwords\n",
    "def remove_stops(text):\n",
    "    ## Tokenize\n",
    "    word_tokens = word_tokenize(text)\n",
    "\n",
    "    ## Remove stopwords\n",
    "    text_tokenized = [word for word in word_tokens if word not in STOPWORDS]\n",
    "\n",
    "    ## Return\n",
    "    return(text_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5668c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to remove urls\n",
    "def remove_urls(text):\n",
    "    ## Remove links\n",
    "    text = re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?Â«Â»â€œâ€â€˜â€™]))''', \" \", text)\n",
    "    \n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e373ab",
   "metadata": {},
   "source": [
    "Emojis are at the very core of communication over social channels. One small image can completely describe one or more human emotions. A naive thing to do during pre-processing would be to remove all emojis. This could result in significant loss of meaning.\n",
    "A good way to achieve this is to replace the emoji with corresponding text explaining the emoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b134b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to replace all emojis in a text with their corresponding meaning in words\n",
    "import demoji\n",
    "def replace_emoji(text):\n",
    "    emoji_text = demoji.findall(text)\n",
    "    return emoji_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac76b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d58bda52",
   "metadata": {},
   "source": [
    "Users sometimes combine multiple words into a single word, where the word disambiguation is done by using capital letters, for example GoodMorning, RainyDay, PlayingInTheCold, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0034f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3e9e5025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a spelling correction library to handle nonstandard spellings\n",
    "#from textblob import TextBlob\n",
    "#def correct_spelling(text):\n",
    "#    text = TextBlob(text).correct()\n",
    "#    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2323058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to remove numbers\n",
    "def remove_numbers(text):\n",
    "    text = \"\".join([char for char in text if char not in NUMBERS])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb277b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1058f7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "236265f3",
   "metadata": {},
   "source": [
    "Next, we create extra features for our model. For some, we first create a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1f61fa",
   "metadata": {},
   "source": [
    "    1) For the number of words, we can just use the function F.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2183bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Define function to count hashtags\n",
    "def get_hashtags(text):\n",
    "    counter = 0\n",
    "    for letter in text:\n",
    "        if letter == \"#\":\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "74a031da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Define function to count tags\n",
    "def get_tags(text):\n",
    "    counter = 0\n",
    "    for letter in text:\n",
    "        if letter == \"@\":\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6a74892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Define a function to get the number of emojis\n",
    "def emoji_counter(text):\n",
    "    nr_emojis = emojis.count(text)\n",
    "    return(nr_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db903cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Define function to count exclamation marks\n",
    "def get_exclamation_marks(text):\n",
    "    counter = 0\n",
    "    for letter in text:\n",
    "        if letter ==  \"!\":\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f4fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3a94c31",
   "metadata": {},
   "source": [
    "    6) the month\n",
    "    8) day of the week\n",
    "    9) hour of the day\n",
    "\n",
    "We saw how to create each of these variables when solving the questions for this assignment. The same code will be used here. This means we need to create one help function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80e0f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayToInt(dayOfWeek):\n",
    "    if(dayOfWeek == \"Mon\"):\n",
    "        return 1\n",
    "    if(dayOfWeek == \"Tue\"):\n",
    "        return 2\n",
    "    if(dayOfWeek == \"Wed\"):\n",
    "        return 3\n",
    "    if(dayOfWeek == \"Thu\"):\n",
    "        return 4\n",
    "    if(dayOfWeek == \"Fri\"):\n",
    "        return 5\n",
    "    if(dayOfWeek == \"Sat\"):\n",
    "        return 6\n",
    "    if(dayOfWeek == \"Sun\"):\n",
    "        return 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2c9889",
   "metadata": {},
   "source": [
    "    10) The variable language is already present.\n",
    "    11) The number of upper case words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20f4ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Define number of upper case words\n",
    "def get_upper_case_words(text):\n",
    "    counter = 0\n",
    "    \n",
    "    ## Tokenize\n",
    "    word_tokens = word_tokenize(text)\n",
    "\n",
    "    ## Check for uppercase words\n",
    "    for word in word_tokens:\n",
    "        if word.isupper():\n",
    "            counter += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b79e92f",
   "metadata": {},
   "source": [
    "    12) tweeted by an influencer or not\n",
    "For this variable, we first have to determine which accounts we consider to be an influencer account. During the data exploration phase, we created a function in order to look at influencers based on 3 characteristics.\n",
    "\n",
    "We define an influencer as an account with the following characteristics:\n",
    "\n",
    "- a lot of followers => follower_count > 10000\n",
    "- there is a high engagement rate on their tweets which shows their influence => er > 0.05\n",
    "- tweet frequency is high enough => freq_weekly > 20\n",
    "\n",
    "This means that we consider about 5% of our tweets comes from an influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050aec68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b56150de",
   "metadata": {},
   "source": [
    "    13) tweeted quote\n",
    "\n",
    "    15) presence of a symbol\n",
    "    16) The age of the account\n",
    "    17) The media type present\n",
    "    18) The number of text characters in the tweet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b402ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Define a function that indicates if the tweet was a quote\n",
    "def tweeted_quote_indicator(quoted):\n",
    "    quote = 0\n",
    "    if quoted == True:\n",
    "        quote = 1\n",
    "    return quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e889ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) define a function that indicates the presence of a symbol\n",
    "def symbol_indicator(symbols):\n",
    "    symbol = 0\n",
    "    if(symbols > 0):\n",
    "        symbol = 1\n",
    "    return symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccd3e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b32cabba",
   "metadata": {},
   "source": [
    "    15) Define the age of the account. This is defined as the number of days since the account has been created and the last day of scraping (2022-10-11). The last day of scraping was calculated in the exploration phase of the data. For this variable, we will use the function datediff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2257f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a0160a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16) define a function to get help get the number of media types included in the tweet\n",
    "def adjust_nr_media(number):\n",
    "    if number == -1:\n",
    "        number = 0\n",
    "        \n",
    "    return number\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "28803641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17) define a function to get the first media element\n",
    "def get_media_type(media):\n",
    "    if media == None:\n",
    "        media = 'no_media'\n",
    "    else:\n",
    "        media = media[0]\n",
    "       \n",
    "    return media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ef53134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18) define a function to get the first media element\n",
    "def get_nr_text_characters(text_range):\n",
    "    number = text_range[1] - text_range[0]  \n",
    "    return number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c048b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19) Look if the user is a verified user\n",
    "def verified_ind(verified):\n",
    "    indicator = 0\n",
    "    if verified == True:\n",
    "        indicator = 1\n",
    "    return indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "17e0c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19, 20 + 21) Besides, we also add some sensitivity parameters\n",
    "def get_sentiment(sentence):\n",
    "\n",
    "    # initialize sentiment analyzer\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # get sentiment dict\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    \n",
    "    # get positive sentiment score\n",
    "    pos_sentiment = sentiment_dict[\"pos\"]\n",
    "    \n",
    "    # return positive sentiment score\n",
    "    return(pos_sentiment)\n",
    "\n",
    "# define function to get polarity score of text \n",
    "def get_polarity(row):\n",
    "    textBlob_review = TextBlob(row)\n",
    "    return textBlob_review.sentiment[0]\n",
    "\n",
    "# define function to get subjectivity score of text \n",
    "def get_subjectivity(row):\n",
    "    textBlob_review = TextBlob(row)\n",
    "    return textBlob_review.sentiment[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd6d80a",
   "metadata": {},
   "source": [
    "Register the functions as udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16e130ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the functions as an udf\n",
    "remove_punct_UDF = F.udf(remove_punct, StringType())\n",
    "remove_urls_UDF = F.udf(remove_urls, StringType())\n",
    "emoji_counter_udf = F.udf(emoji_counter, IntegerType())\n",
    "replace_emoji_UDF = F.udf(replace_emoji, StringType())\n",
    "remove_numbers_UDF = F.udf(remove_numbers, StringType())\n",
    "get_upper_case_words_UDF = F.udf(get_upper_case_words, IntegerType()) \n",
    "tokenize_and_remove_stops_UDF = F.udf(remove_stops, ArrayType(StringType()))\n",
    "get_hashtags_udf = F.udf(get_hashtags, IntegerType())\n",
    "get_tags_udf = F.udf(get_tags, IntegerType())\n",
    "get_exclamation_marks_UDF = F.udf(get_exclamation_marks, IntegerType())\n",
    "convert_dayToInt_UDF = F.udf(dayToInt, StringType())\n",
    "tweeted_quote_indicator_UDF = F.udf(tweeted_quote_indicator, IntegerType())\n",
    "symbol_indicator_udf = F.udf(symbol_indicator, IntegerType())\n",
    "adjust_nr_media_udf = F.udf(adjust_nr_media, IntegerType())\n",
    "get_media_type_udf = F.udf(get_media_type, StringType())\n",
    "get_nr_text_characters_udf = F.udf(get_nr_text_characters, IntegerType())\n",
    "verified_ind_udf = F.udf(verified_ind, IntegerType())\n",
    "get_sentiment_udf = F.udf(get_sentiment, DoubleType())\n",
    "get_polarity_udf = F.udf(get_polarity, DoubleType())\n",
    "get_subjectivity_udf = F.udf(get_subjectivity, DoubleType())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "201bf933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the final basetable for our analysis\n",
    "basetable_engr_final = basetable_engr.withColumn(\"nr_emojis\", emoji_counter_udf(F.col(\"full_text\")))\\\n",
    "                            .withColumn('emojis_text', replace_emoji_UDF('full_text'))\\\n",
    "                            .withColumn('upper_case_words', get_upper_case_words_UDF('emojis_text'))\\\n",
    "                            .withColumn('text_lower', F.lower('full_text'))\\\n",
    "                            .withColumn('clean_punct', remove_punct_UDF('text_lower'))\\\n",
    "                            .withColumn('clean_urls', remove_urls_UDF('clean_punct'))\\\n",
    "                            .withColumn('clean_numbers', remove_numbers_UDF('clean_urls'))\\\n",
    "                            .withColumn('text_tokinezed_no_stops', tokenize_and_remove_stops_UDF('clean_numbers'))\\\n",
    "                            .withColumn(\"num_words\", F.size(\"text_tokinezed_no_stops\")) \\\n",
    "                            .withColumn(\"num_hashtags\", get_hashtags_udf(\"text_tokinezed_no_stops\")) \\\n",
    "                            .withColumn(\"num_mentions\", get_tags_udf(\"text_tokinezed_no_stops\")) \\\n",
    "                            .withColumn('nr_exlcamations', get_exclamation_marks_UDF('text_tokinezed_no_stops'))\\\n",
    "                            .withColumn(\"week_day\", F.date_format(F.col(\"tweet_created\"), \"E\"))\\\n",
    "                            .withColumn(\"week_day\", convert_dayToInt_UDF(\"week_day\"))\\\n",
    "                            .withColumn(\"hour\", F.date_format(F.col(\"tweet_created\"), \"H\").cast('int'))\\\n",
    "                            .withColumn(\"month\", F.date_format(F.col(\"tweet_created\"), \"M\").cast('int'))\\\n",
    "                            .withColumn('quoted_ind', tweeted_quote_indicator_UDF('quoted'))\\\n",
    "                            .withColumn('symbol_ind', F.size('symbols'))\\\n",
    "                            .withColumn('symbols_ind', symbol_indicator_udf('symbol_ind'))\\\n",
    "                            .withColumn('user_age_days', F.datediff(F.lit(\"2022-10-11\"), F.col(\"user_created\")))\\\n",
    "                            .withColumn('verified', verified_ind_udf('user_verified'))\\\n",
    "                            .withColumn(\"nr_media_elements\", F.size(\"media_type\"))\\\n",
    "                            .withColumn(\"nr_media_elements\", adjust_nr_media_udf(\"nr_media_elements\"))\\\n",
    "                            .withColumn(\"media_type\", get_media_type_udf('media_type'))\\\n",
    "                            .withColumn(\"nr_text_char\", get_nr_text_characters_udf('text_range'))\\\n",
    "                            .drop('clean_punct')\\\n",
    "                            .drop('clean_urls')\\\n",
    "                            .drop('text_lower')\\\n",
    "                            .drop('clean_numbers')\\\n",
    "                            .drop('week_day')\\\n",
    "                            .drop('post_created_at')\\\n",
    "                            .drop('quoted')\\\n",
    "                            .drop('symbols')\\\n",
    "                            .drop('user_created')\\\n",
    "                            .drop('user_verified')\\\n",
    "                            .drop('display_text_range')\\\n",
    "                            .filter(\"num_words > 0\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d81be41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>text_tokinezed_no_stops</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>emojis_text</th>\n",
       "      <th>nr_exlcamations</th>\n",
       "      <th>eng_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This afternoon, live-streaming a relaxed conve...</td>\n",
       "      <td>[afternoon, livestreaming, relaxed, conversati...</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sweet Potato &amp;amp; Courgette Fritters with Min...</td>\n",
       "      <td>[sweet, potato, amp, courgette, fritters, mint...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy mushroom bucatini #vegan #veganforlife ...</td>\n",
       "      <td>[creamy, mushroom, bucatini, #, vegan, #, vega...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>{}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Polypieter veggie is al super!\\nvegan is quas...</td>\n",
       "      <td>[@, polypieter, veggie, al, super, !, vegan, q...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>{ðŸ˜¥=sad but relieved face}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enriched with natural origin ingredients certi...</td>\n",
       "      <td>[enriched, natural, origin, ingredients, certi...</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>{ðŸ˜‰=winking face}</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  This afternoon, live-streaming a relaxed conve...   \n",
       "1  Sweet Potato &amp; Courgette Fritters with Min...   \n",
       "2  Creamy mushroom bucatini #vegan #veganforlife ...   \n",
       "3  @Polypieter veggie is al super!\\nvegan is quas...   \n",
       "4  Enriched with natural origin ingredients certi...   \n",
       "\n",
       "                             text_tokinezed_no_stops  num_words  num_hashtags  \\\n",
       "0  [afternoon, livestreaming, relaxed, conversati...         22             6   \n",
       "1  [sweet, potato, amp, courgette, fritters, mint...         13             2   \n",
       "2  [creamy, mushroom, bucatini, #, vegan, #, vega...         10             3   \n",
       "3  [@, polypieter, veggie, al, super, !, vegan, q...         44             1   \n",
       "4  [enriched, natural, origin, ingredients, certi...         20             4   \n",
       "\n",
       "                 emojis_text  nr_exlcamations  eng_rate  \n",
       "0                         {}                0  0.001179  \n",
       "1                         {}                0  0.003097  \n",
       "2                         {}                0  0.027938  \n",
       "3  {ðŸ˜¥=sad but relieved face}                1  0.000000  \n",
       "4           {ðŸ˜‰=winking face}                0  0.000000  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable_engr_final.select(\"full_text\", \"text_tokinezed_no_stops\", \"num_words\", \"num_hashtags\", \"emojis_text\", \"nr_exlcamations\", \"eng_rate\").toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff1842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1ddde0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4daff2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41fa4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c353f98",
   "metadata": {},
   "source": [
    "- Create 15 new columns in the dataframe and drop the necessary variables:\n",
    "        1. number of words by using the F.size() function\n",
    "        2. number of hashtags by using udf\n",
    "        3. number of tags by using udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ef5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features\n",
    "basetable_engr = basetable_engr.withColumn(\"num_words\", F.size(\"text_tokenized_no_stops\"))\\\n",
    "                                         .withColumn(\"num_hashtags\", get_hashtags_udf(\"text_tokenized_no_stops\")) \\\n",
    "                                         .withColumn(\"num_tags\", get_tags_udf(\"text_tokenized_no_stops\"))\\\n",
    "                                         .withColumn(\"num_tags\", get_tags_udf(\"text_tokenized_no_stops\"))\\\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c5b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d72cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6503ce7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2cbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
